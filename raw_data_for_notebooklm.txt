

==================== 来自文件: data/问答题/1.json ====================

题目: 汤姆·米切尔（Tom Mitchell）对机器学习的定义是什么？
答案: 计算机程序如何随着<b>经验积累</b>自动提高性能，系统自我改进的过程；或计算机利用经验改善系统自身性能的行为。
----------------------------------------
题目: 机器学习的核心思想是什么？
答案: 从数据中发现<b>模式</b> -> 做出<b>预测或决策</b>。
----------------------------------------
题目: 机器学习与传统编程的一个主要区别是什么（关于数据和规则）？
答案: 传统编程是显式编程；机器学习是从数据中自动学习和改进，从数据中获取知识（数据驱动决策）。
----------------------------------------
题目: 自然智慧的两个重要特点是什么（机器学习希望模仿的）？
答案: 1. <b>容错性</b><br>2. <b>推广能力</b>（举一反三/泛化能力）
----------------------------------------
题目: 什么是“有监督学习”（Supervised Learning）？
答案: 在<b>样本标签已知</b>的情况下，利用这些参数进行分类器设计。训练样本已经标注（Labeled）。<br>典型应用：分类、回归。
----------------------------------------
题目: 什么是“无监督学习”（Unsupervised Learning）？
答案: 在<b>无法预先知道样本标签</b>（无训练样本/Unlabeled）的情况下进行分类器设计。<br>典型应用：聚类、模式发现。
----------------------------------------
题目: “分类”（Classification）与“聚类”（Clustering）的主要区别是什么？
答案: <b>分类</b>：属于有监督学习，类别是已知的。<br><b>聚类</b>：属于无监督学习，类别是学习出来的（未知的）。
----------------------------------------
题目: 什么是“懒惰学习”（Lazy Learning）？及其主要目的？
答案: <b>定义</b>：平时仅保存数据，不主动建模，直到预测时才处理数据。<br><b>目的</b>：从输入输出数据对构成的训练集中学习输入到输出的映射关系。
----------------------------------------
题目: 懒惰学习（Lazy Learning）的三个显著特征是什么？
答案: 1. <b>延迟学习</b>（预测时才处理，平时不建模）<br>2. <b>局部估计</b>（只依赖与查询点相关的数据）<br>3. <b>即时计算</b>（预测后不保留中间结果）
----------------------------------------
题目: 机器学习发展史：1957年谁首次提出了感知器（Perceptron）？
答案: Rosenblatt
----------------------------------------
题目: 机器学习发展史：1969年《Perceptron》一书指出了感知器无法解决什么著名问题？
答案: <b>XOR 问题</b>（异或问题）。这也导致了神经网络研究的第一次低潮。
----------------------------------------
题目: 机器学习发展史：1980年代，什么算法成功解决了XOR问题，标志着连接主义（神经网络）的复兴？
答案: <b>MLP + BP算法</b>（多层感知机 + 反向传播算法）。
----------------------------------------
题目: 机器学习发展史：1990年代统计学习理论走向成熟的典型代表算法是什么？
答案: <b>SVM</b>（支持向量机）。<br>代表人物：Vapnik。
----------------------------------------
题目: SVM（支持向量机）基于什么原则？
答案: <b>结构风险最小化</b>原则。
----------------------------------------
题目: 机器学习发展史：2012年发生的标志性事件是什么？
答案: <b>深度学习</b>（Deep Learning）兴起。<br>深度学习方法在 <b>ImageNet</b> 竞赛中取得了最佳效果，显著提升了性能。
----------------------------------------
题目: 机器学习发展史：2016年，Google的什么系统战胜了李世石？
答案: <b>AlphaGo</b>
----------------------------------------
题目: 机器学习受到哪些相关学科的影响？（列举3-4个）
答案: 1. <b>人工智能</b>（符号表示、Bayes）<br>2. <b>统计学</b>（统计学习理论 SLT）<br>3. <b>信息论</b>（最小描述长度）<br>4. <b>哲学</b>（奥卡姆剃刀、没有免费午餐）<br>5. <b>神经生物学</b>（神经网络）
----------------------------------------
题目: 在网络安全领域，入侵检测通常被看作哪种类型的机器学习问题？
答案: 典型的<b>预测型</b>机器学习问题（通常是有监督的分类问题，区分正常访问与入侵模式）。
----------------------------------------
题目: Google搜索引擎的第一桶金来源于哪个基于机器学习的算法？
答案: <b>PageRank</b> 算法
----------------------------------------
题目: 对于“奥卡姆剃刀”（Occam's Razor）原则在机器学习中的理解通常是什么？
答案: “如无必要，勿增实体”。<br>在性能相近的模型中，通常选择<b>更简单</b>的模型（以提高泛化能力）。
----------------------------------------
题目: 机器学习中的“概念学习”（Concept Learning）是指什么？
答案: 从有关某个<b>布尔函数</b>的输入输出训练样例中，推断出该布尔函数。<br>（也可以看作是从特殊的训练样例中归纳出一般函数）
----------------------------------------
题目: 概念学习可以被看作是什么样的搜索过程？
答案: 在预定义的<b>假设空间</b>中进行搜索，寻找能够最好地拟合训练样例的假设。
----------------------------------------
题目: 在概念学习中，“归纳学习假设”（Inductive Learning Hypothesis）的内容是什么？
答案: 任一假设如果在足够大的训练样例集中很好地逼近目标函数，它也能在<b>未见实例</b>中很好地逼近目标函数。<br>（即：对未见实例最好的假设就是与训练数据最佳拟合的假设）
----------------------------------------
题目: 在假设空间中，什么是“一般到特殊”的序关系（More General）？
答案: 当且仅当对于任意实例 $x$，只要 $h_k(x)=1$ 就能推出 $h_j(x)=1$ 时，称 $h_j$ 比 $h_k$ <b>更一般</b>（或 $h_j \ge_g h_k$）。<br>简单来说，更一般的假设覆盖了更多的正例。
----------------------------------------
题目: 假设空间上的“一般到特殊”序关系属于哪种数学关系？
答案: <b>偏序关系</b>（Partial Order）。<br>（注：不是全序，因为有些假设之间无法比较谁更一般）
----------------------------------------
题目: Find-S 算法的基本策略是什么？
答案: 寻找<b>极大特殊</b>假设。<br>初始化为最特殊的假设，遇到正例时，将假设进行极小一般化以覆盖该正例；遇到反例时忽略。
----------------------------------------
题目: Find-S 算法的主要缺点有哪些？
答案: 1. 无法判断找到的假设是否是唯一的。<br>2. <b>容错性差</b>（对噪声敏感），若训练样例有误，结果会出错。<br>3. 无法利用反例的信息。
----------------------------------------
题目: 什么是“变型空间”（Version Space）？
答案: 假设空间 $H$ 中与训练样例集 $D$ <b>一致</b>的所有假设组成的子集。<br>（即：$VS_{H,D} = \{h \in H | Consistent(h, D)\}$）
----------------------------------------
题目: 在变型空间中，“一致”（Consistent）的定义是什么？
答案: 一个假设 $h$ 与训练样例集合 $D$ 一致，当且仅当对 $D$ 中每一个样例 $<x, c(x)>$，都有 $h(x) = c(x)$。
----------------------------------------
题目: 候选消除算法（Candidate-Elimination）如何表示变型空间？
答案: 通过维护两个边界集合来简洁地表示：<br>1. <b>S边界</b>（极大特殊边界）：与数据一致的极大特殊成员集合。<br>2. <b>G边界</b>（极大一般边界）：与数据一致的极大一般成员集合。
----------------------------------------
题目: 在候选消除算法中，遇到“正例”时如何更新 S 和 G？
答案: 1. <b>S边界</b>：进行<b>极小一般化</b>（变得更一般以包含新正例），同时移除与新数据不一致的假设。<br>2. <b>G边界</b>：移除与新正例不一致的假设（变得更特殊通常不需要，除非冲突）。
----------------------------------------
题目: 在候选消除算法中，遇到“反例”时如何更新 S 和 G？
答案: 1. <b>S边界</b>：移除与新反例不一致的假设。<br>2. <b>G边界</b>：进行<b>极小特殊化</b>（变得更特殊以排除新反例），且需保证特殊化后的假设仍比S中的某个成员更一般。
----------------------------------------
题目: 概念学习中，最优的查询策略（选择下一个训练样例）是什么？
答案: 产生一个实例，使其满足当前变型空间中<b>大约半数</b>的假设。<br>这样可以将变型空间的大小减半（类似于二分查找），理论上只需 $\log_2|VS|$ 次实验。
----------------------------------------
题目: 候选消除算法什么时候会收敛到一个空的变型空间？
答案: 当训练样例中<b>存在错误</b>（噪声），或者<b>目标概念无法被假设空间表示</b>（例如目标概念是析取形式，但假设空间只限于合取）时。
----------------------------------------
题目: 什么是“归纳偏置”（Inductive Bias）？
答案: 学习器为了从训练数据中归纳出未见实例的分类，所必须做出的<b>前提假设</b>（集合 B）。<br>如果没有偏置，学习器只能进行死记硬背（Rote Learning），无法泛化。
----------------------------------------
题目: 候选消除算法（Candidate-Elimination）的归纳偏置是什么？
答案: 目标概念 <b>$c$ 包含在假设空间 $H$ 中</b>。
----------------------------------------
题目: 无偏的学习器（Unbiased Learner）存在什么问题？
答案: <b>无偏学习是无用的</b>。<br>如果不对目标概念的形式做任何预先假定（例如允许它是实例集的任意子集），那么它根本无法对未见实例进行分类（无法泛化）。
----------------------------------------
题目: 按照归纳偏置（Bias）的强弱，排列 Find-S、候选消除算法和机械式学习（Rote Learning）。
答案: Find-S > 候选消除算法 > 机械式学习<br>（偏置越强，归纳能力越强，但也越容易因为假设错误而失败）
----------------------------------------
题目: 在 EnjoySport 例子中，如果 Sky 属性有 3 种值，其他 5 个属性各有 2 种值。语法上不同的假设有多少种？（包含 ? 和 $\emptyset$）
答案: 计算公式：$(3+2) \times (2+2)^5 = 5 \times 4^5 = 5120$ 种。<br>（每个属性可以是特定值、? 或 $\emptyset$）
----------------------------------------
题目: 在 EnjoySport 例子中，为什么语义上不同的假设只有 973 个？
答案: 因为包含 $\emptyset$（空集/全反例）的假设在语义上是等价的（都把所有实例分为反例）。<br>计算：$1$ (全反例) $+ (3+1) \times (2+1)^5 = 1 + 4 \times 3^5 = 1 + 972 = 973$。
----------------------------------------


==================== 来自文件: data/问答题/2.json ====================

题目: 线性模型（Linear Model）的一般向量形式是什么？
答案: $$f(x) = <b>w^T x + b</b>$$<br>其中 $w$ 为<b>权重</b>向量，$b$ 为<b>偏置</b>。
----------------------------------------
题目: 线性回归中，如何处理“无序”的离散属性？
答案: 将其转化为 <b>k维向量</b>（通常使用<b>独热编码</b> One-hot encoding）。<br>例如：颜色={红, 黄, 蓝} -> (0,0,1), (0,1,0)...
----------------------------------------
题目: 线性回归最常用的参数估计方法是什么？
答案: <b>最小二乘法</b> (Least Square Method)。<br>目标是最小化<b>均方误差</b>（MSE）。
----------------------------------------
题目: 当数据矩阵 $X^TX$ 不满秩或样本量极大时，通常使用什么方法求解线性回归参数？
答案: <b>梯度下降</b>法 (Gradient Descent)。
----------------------------------------
题目: 什么是广义线性模型 (Generalized Linear Model)？
答案: $$y = g^{-1}(w^T x + b)$$<br>其中 $g(\cdot)$ 称为<b>联系函数</b> (Link Function)，它将线性模型的预测值与真实标记联系起来。
----------------------------------------
题目: 什么是岭回归 (Ridge Regression)？其核心特点是什么？
答案: 在平方误差的基础上增加了 <b>L2范数</b>正则化项 ($|w|_2^2$)。<br>特点：收缩系数，处理<b>多重共线性</b>，但不会将系数压缩为0。
----------------------------------------
题目: 什么是 Lasso 回归？其核心特点是什么？
答案: 在平方误差的基础上增加了 <b>L1范数</b>正则化项 ($|w|_1$)。<br>特点：能获得<b>稀疏解</b>（将部分系数压缩为0），因此可用于<b>特征选择</b>。
----------------------------------------
题目: 用形象的比喻描述岭回归 (Ridge) 和 Lasso 的区别？
答案: <b>岭回归</b>像公平的管理者：每个部门（特征）预算都<b>削减一点</b>，不完全砍掉。<br><b>Lasso</b>像果断的决策者：保留关键部门，不重要的直接<b>砍掉</b>（系数置0）。
----------------------------------------
题目: 什么是弹性网络 (Elastic Net)？
答案: 结合了 <b>L1</b> (Lasso) 和 <b>L2</b> (Ridge) 两种正则化项的模型。<br>既具有<b>稀疏性</b>，又具有<b>稳定性</b>。
----------------------------------------
题目: 为什么不能直接用线性回归 (Linear Regression) 做分类任务？
答案: 1. <b>输出范围</b>不匹配：回归输出是连续值，分类需要离散值或概率。<br>2. 对<b>异常值敏感</b>：均方误差对远离边界的点惩罚过大，导致决策边界偏移。
----------------------------------------
题目: 对数几率回归 (Logistic Regression) 使用什么函数将线性输出映射为概率？
答案: <b>Sigmoid</b> 函数 (或对数几率函数)：<br>$$y = \frac{1}{1 + e^{-z}}$$
----------------------------------------
题目: 对数几率回归 (Logistic Regression) 通常使用什么方法进行参数估计？
答案: <b>极大似然法</b> (Maximum Likelihood Estimation)，即最小化负对数似然函数。
----------------------------------------
题目: Softmax 回归适用于什么场景？
答案: 适用于<b>多分类</b>问题。<br>它是逻辑回归在多分类上的推广。
----------------------------------------
题目: 感知机 (Perceptron) 的激活函数是什么？
答案: <b>符号函数</b> (Sign function)：<br>输出 +1 或 -1。
----------------------------------------
题目: 单层感知机 (Perceptron) 的最大局限性是什么？
答案: 只能解决<b>线性可分</b>问题，无法解决 <b>异或</b> (XOR) 等非线性问题。
----------------------------------------
题目: 线性判别分析 (LDA) 的核心思想是什么（一句话概括）？
答案: <b>最大化类间散度</b>，<b>最小化类内散度</b>。<br>（让同类样例尽可能接近，异类样例尽可能远离）。
----------------------------------------
题目: LDA (线性判别分析) 除了用于分类，还可以被视为一种什么技术？
答案: 一种<b>监督降维</b>技术。
----------------------------------------
题目: 在多分类学习中，常用的拆分策略有哪些？
答案: 1. <b>一对一</b> (OvO)：训练 $N(N-1)/2$ 个分类器，投票决定。<br>2. <b>一对其余</b> (OvR/OvA)：训练 $N$ 个分类器，取置信度最高的。
----------------------------------------
题目: 欠拟合 (Underfitting) 的主要原因及解决办法？
答案: <b>原因</b>：<b>特征维度过少</b>，模型太简单。<br><b>解决</b>：增加特征维度，引入<b>非线性特征</b>。
----------------------------------------
题目: 过拟合 (Overfitting) 的主要原因及解决办法？
答案: <b>原因</b>：特征维度过多，模型太复杂，拟合了<b>噪声</b>。<br><b>解决</b>：减少特征、<b>正则化</b> (Ridge/Lasso)、数据集扩增、早停等。
----------------------------------------
题目: 什么是基函数扩展 (Basis Function Expansion)？
答案: 通过基函数 $\phi(x)$ 将原始特征映射到<b>更高维</b>空间，在新空间中用线性模型解决原空间的<b>非线性</b>问题。
----------------------------------------
题目: 解决类别不平衡 (Class Imbalance) 问题的三种常见方法？
答案: 1. <b>再缩放</b>/阈值移动 (Rescaling)。<br>2. <b>欠采样</b> (Undersampling)。<br>3. <b>过采样</b> (Oversampling)。
----------------------------------------
题目: SMOTE 算法的基本原理是什么？
答案: 属于<b>过采样</b>方法。<br>不是简单复制样本，而是在少数类样本之间进行<b>线性插值</b>生成新样本，以避免过拟合。
----------------------------------------


==================== 来自文件: data/问答题/3.json ====================

题目: 分类（Classification）与回归（Regression）的主要区别是什么？
答案: **分类**：目标属性 $y$ 是<b>离散</b>的（类别标签）。<br>**回归**：目标属性 $y$ 是<b>连续</b>的（实数值）。
----------------------------------------
题目: 决策树中的内部节点（Internal Node）、分支（Branch）和叶子节点（Leaf Node）分别代表什么？
答案: 1. **内部节点**：对实例的某个<b>属性</b>的测试。<br>2. **分支**：该属性的一个可能<b>取值</b>。<br>3. **叶子节点**：实例所属的<b>分类</b>（类标号）。
----------------------------------------
题目: 从逻辑表达式的角度看，决策树代表了什么形式的规则？
答案: 代表了实例属性值约束的<b>合取的析取式</b>（Disjunction of Conjunctions）。<br>即：(条件A AND 条件B) OR (条件C AND 条件D)...
----------------------------------------
题目: ID3 算法采用什么样的搜索策略？
答案: <b>自顶向下</b>的<b>贪婪搜索</b>（Greedy Search），遍历可能的决策树空间。<br>（注：它不进行回溯，因此可能收敛到局部最优）。
----------------------------------------
题目: 信息熵（Entropy）的数学公式及其含义是什么？
答案: 公式：$Entropy(S) = - \sum p_i \log_2 p_i$<br>含义：度量样本集合的<b>纯度</b>或<b>不确定性</b>。<br>熵越小，集合越纯（所有样本属于同一类）；熵越大，集合越混乱。
----------------------------------------
题目: 如果一个样本集合 $S$ 中正反样例数量相等，其熵值为多少？如果所有成员属于同一类，熵值为多少？
答案: 1. 正反相等：Entropy(S) = <b>1</b>。<br>2. 属于同一类：Entropy(S) = <b>0</b>。
----------------------------------------
题目: ID3 算法使用什么指标来选择最佳划分属性？
答案: <b>信息增益</b> (Information Gain)。<br>它是指由于使用某个属性分割样例而导致的<b>期望熵降低</b>。
----------------------------------------
题目: 信息增益（Information Gain）准则的一个主要缺点是什么？
答案: 它存在内在偏置，<b>偏向于选择取值较多</b>的属性。<br>（例如：如果有一个属性是唯一的“ID号”，它的信息增益最大，但不仅没有泛化能力，还会导致过拟合）。
----------------------------------------
题目: ID3 算法的归纳偏置（Inductive Bias）是什么？（即奥卡姆剃刀原则在决策树中的体现）
答案: <b>优先选择较短的树</b>，以及将信息增益高的属性放在离根节点较近的地方。<br>（简单假设优于复杂假设）。
----------------------------------------
题目: C4.5 算法相对于 ID3 算法做了哪些主要改进？（列举至少3点）
答案: 1. 使用<b>信息增益比</b>（Gain Ratio）代替信息增益，克服偏向多值属性的缺点。<br>2. 能够处理<b>连续值</b>属性（离散化）。<br>3. 能够处理<b>缺失值</b>。<br>4. 引入了<b>剪枝</b>（Pruning）机制以防止过拟合。
----------------------------------------
题目: 信息增益比（Gain Ratio）是如何修正信息增益的？
答案: 它在信息增益的基础上除以了<b>分裂信息</b>（SplitInformation），即引入了对属性分裂广度和均匀性的惩罚项。
----------------------------------------
题目: CART 算法的全称是什么？它构建的是什么类型的树？
答案: **CART** = Classification and Regression Trees（分类与回归树）。<br>它构建的是<b>二叉树</b>（Binary Tree）。
----------------------------------------
题目: CART 算法在分类任务和回归任务中分别使用什么指标作为划分标准？
答案: 1. **分类**：使用<b>基尼指数</b> (Gini Index)。<br>2. **回归**：使用<b>均方误差</b> (MSE) 或平方误差和。
----------------------------------------
题目: 基尼指数（Gini Index）的公式是什么？它反映了什么？
答案: 公式：$Gini(S) = 1 - \sum p_i^2$<br>含义：反映了从数据集中随机抽取两个样本，其类别标记不一致的概率。<b>基尼值越小，纯度越高</b>。
----------------------------------------
题目: 什么是决策树的“过拟合”（Overfitting）？
答案: 假设 $h$ 在训练集上的表现很好（错误率低），但在新的<b>测试集</b>（整个实例分布）上的表现比另一个假设 $h'$ 差。即模型把训练数据中的<b>噪声</b>或巧合规律也学习了，导致泛化能力下降。
----------------------------------------
题目: 决策树防止过拟合的两种主要策略是什么？
答案: 1. <b>预剪枝</b> (Pre-pruning)：在树生长过程中及早停止（如限制深度、样本数）。<br>2. <b>后剪枝</b> (Post-pruning)：先让树充分生长，然后自底向上修剪掉无助于提高验证集精度的分支。
----------------------------------------
题目: C4.5 算法如何处理连续值属性？
答案: 采用<b>二分法</b>。<br>将连续属性的取值排序，取相邻两个值的<b>中点</b>作为候选分裂点（阈值），计算每个分裂点的信息增益，选择最优的阈值将连续属性离散化为二元属性。
----------------------------------------
题目: 在决策树学习中，如何处理缺失属性值的训练样例？（列举常见策略）
答案: 1. 赋给它当前节点训练样例中该属性的<b>最常见值</b>。<br>2. 赋给它当前节点属于同一类别（$y$）的训练样例中该属性的最常见值。<br>3. 为该属性的每个可能值赋予一个<b>概率权重</b>（C4.5采用的方法）。
----------------------------------------
题目: 决策树的“规则后修剪”（Rule Post-Pruning）的基本过程是什么？
答案: 1. 允许决策树过度拟合。<br>2. 将树转化为<b>等价的规则集合</b>（每条路径一条规则）。<br>3. 修剪规则中不会导致精度降低的前件（Preconditions）。<br>4. 对规则集进行排序应用。
----------------------------------------


==================== 来自文件: data/问答题/4.json ====================

题目: 人工神经元模型（Artificial Neuron）主要由哪几个部分组成？
答案: 1. <b>输入</b> ($x$)：对应生物神经元的树突。<br>2. <b>权值</b> ($w$)：对应突触的连接强度。<br>3. <b>加权求和</b> ($\sum$)：对应细胞体的信息累积。<br>4. <b>激活</b>/输出函数 ($f$)：对应阈值判断和脉冲输出。
----------------------------------------
题目: 感知器（Perceptron）的定义及其输出规则是什么？
答案: 感知器是一个<b>线性分类</b>模型。<br>它计算输入的线性组合，如果结果大于某个阈值，输出 <b>1</b>，否则输出 <b>-1</b>。<br>公式：$o(\vec{x}) = \text{sgn}(\vec{w} \cdot \vec{x})$
----------------------------------------
题目: 感知器（Perceptron）无法解决哪类著名的逻辑问题？为什么？
答案: 无法解决 <b>异或</b> (XOR) 问题。<br>原因：感知器本质上是一个<b>线性分类器</b>（超平面），而 XOR 问题是<b>线性不可分</b>的。
----------------------------------------
题目: 感知器训练法则（Perceptron Training Rule）的权值更新公式是什么？
答案: $$w_i \leftarrow w_i + \eta (t - o) x_i$$<br>其中 $\eta$ 是<b>学习率</b>，$t$ 是目标值，$o$ 是实际输出，$x_i$ 是输入。
----------------------------------------
题目: 感知器训练法则能够收敛的前提条件是什么？
答案: 1. 训练样例是<b>线性可分</b>的。<br>2. <b>学习率</b> $\eta$ 足够小。
----------------------------------------
题目: 什么是 Delta 法则（Delta Rule）？它与感知器法则的主要区别是什么？
答案: Delta 法则使用<b>梯度下降</b>（Gradient Descent）来最小化误差平方和。<br><b>区别</b>：Delta 法则即使在数据<b>线性不可分</b>时也能收敛到目标概念的最佳近似（最小误差），而感知器法则无法保证。
----------------------------------------
题目: 在神经网络训练中，标准梯度下降（Batch）与随机梯度下降（SGD）的主要区别是什么？
答案: **标准梯度下降**：在更新权值前对<b>所有</b>样例汇总误差。计算量大，但步长可稍大。<br>**随机梯度下降**：每处理<b>一个</b>样例就更新一次权值。计算快，可能避免<b>局部极小值</b>，但路径震荡。
----------------------------------------
题目: 为什么多层前馈网络中通常使用 Sigmoid 单元而不是感知器单元（阶跃函数）？
答案: 因为感知器的阶跃函数是不连续、<b>不可微</b>的，无法应用基于梯度的优化算法（如反向传播）。<br>Sigmoid 函数是平滑、连续且<b>处处可导</b>的。
----------------------------------------
题目: 反向传播算法（BP）的核心思想是什么？
答案: 利用<b>链式法则</b>，将输出层的误差<b>反向传播</b>回隐藏层，从而计算出每个权值对总误差的贡献（<b>梯度</b>），并据此调整权值。
----------------------------------------
题目: 在反向传播中，输出单元 $k$ 的误差项 $\delta_k$ 如何计算？（Sigmoid激活函数）
答案: $$\delta_k = o_k(1 - o_k)(t_k - o_k)$$<br>包含三部分：输出值的<b>导数</b> $o_k(1-o_k)$ 和 预测<b>误差</b> $(t_k - o_k)$。
----------------------------------------
题目: 在反向传播中，隐藏层单元 $h$ 的误差项 $\delta_h$ 是如何得到的？
答案: 通过对受该隐层单元影响的所有下游单元的误差 $\delta_k$ 进行<b>加权求和</b>（权重为 $w_{kh}$），再乘在该隐层单元的激活函数<b>导数</b>。<br>即：利用下游误差来“归咎”上游节点。
----------------------------------------
题目: 在梯度下降中加入“冲量项”（Momentum）有什么作用？
答案: 1. 像球滚下山坡一样，利用惯性冲过狭窄的<b>局部极小值</b>或平坦区域。<br>2. 在梯度不变区域增大搜索步长，<b>加快收敛</b>。<br>公式：$\Delta w(n) = \eta \delta x + \alpha \Delta w(n-1)$
----------------------------------------
题目: 多层前馈神经网络（Multi-layer Feedforward NN）的表征能力如何？（通用近似定理）
答案: 1. <b>布尔函数</b>：两层网络可表示任意布尔函数。<br>2. <b>连续函数</b>：包含一个隐层的网络可以以任意精度<b>逼近</b>任何有界连续函数。
----------------------------------------
题目: 反向传播算法的归纳偏置（Inductive Bias）是什么？
答案: 倾向于在数据点之间进行<b>平滑插值</b>。<br>（即给定两个正例，倾向于把中间的点也标记为正例）。
----------------------------------------
题目: 神经网络训练中，为什么会出现“过度拟合”（Overfitting）？现象是什么？
答案: <b>原因</b>：权值迭代次数过多，模型变得过于复杂，拟合了数据中的<b>噪声</b>或特异性特征。<br><b>现象</b>：训练集误差持续下降，但<b>验证集误差</b>先下降后上升。
----------------------------------------
题目: 解决神经网络过拟合的常用方法有哪些？（至少列举2种）
答案: 1. <b>权值衰减</b>（Weight Decay）：在误差函数中加入权值大小的惩罚项。<br>2. <b>早停法</b>（Early Stopping）：使用验证集，当验证误差开始上升时停止训练。<br>3. <b>交叉验证</b>：确定最佳的隐层单元数或迭代次数。
----------------------------------------
题目: 循环神经网络（RNN）与前馈神经网络最大的区别是什么？
答案: RNN 具有<b>记忆</b>（Memory）。<br>RNN 的层内、层与层之间有反馈连接，当前时刻的输出不仅取决于当前输入，还取决于<b>上一时刻</b>的隐状态。适合处理<b>序列数据</b>（如NLP）。
----------------------------------------
题目: LSTM（长短期记忆网络）主要是为了解决 RNN 的什么问题？
答案: 解决简单 RNN 在处理长序列时出现的<b>梯度消失</b>（或梯度爆炸）问题，使其能够捕捉<b>长期依赖</b>（Long-term dependencies）关系。
----------------------------------------
题目: 在人脸识别案例中，为什么输出层采用 1-of-n 编码（如4个输出单元）而不是单个输出单元？
答案: 1. 为网络表示目标函数提供更大的<b>自由度</b>。<br>2. 输出值的分布（如0.9, 0.1, 0.1, 0.1）可以表示分类的<b>置信度</b>。
----------------------------------------
题目: 在人脸识别案例中，为什么目标值设为 <0.9, 0.1...> 而不是 <1, 0...>？
答案: 因为 Sigmoid 函数仅在输入趋于无穷大时才输出 1 或 0。<br>如果强行拟合 1 或 0，会导致<b>权值无限增长</b>，引发过拟合或梯度问题。
----------------------------------------


==================== 来自文件: data/问答题/5.json ====================

题目: 贝叶斯学习（Bayesian Learning）的核心假定是什么？
答案: 待考察的量遵循某<b>概率分布</b>，且可根据这些概率及已观察到的数据进行推理，以作出最优的决策。
----------------------------------------
题目: 相比于其他非概率学习算法，贝叶斯学习方法的一个最大优点是什么？
答案: 观察到的每个训练样例可以<b>增量地</b>降低或升高某假设的估计概率。而其它算法通常会在某个假设与任一样例不一致时完全去掉该假设。
----------------------------------------
题目: 在贝叶斯学习中，什么是先验概率（Prior Probability）？
答案: 在没有训练数据前假设 $h$ 拥有的<b>初始概率</b> $P(h)$，它反映了关于 $h$ 是一正确假设的机会的背景知识。
----------------------------------------
题目: 在贝叶斯学习中，什么是后验概率（Posterior Probability）？
答案: 给定数据 $D$ 时假设 $h$ 成立的概率 $P(h|D)$。它是<b>先验</b>信息和<b>样本</b>信息的综合。
----------------------------------------
题目: 贝叶斯公式（Bayes Theorem）的数学表达式是什么？
答案: $$P(h|D) = \frac{<b>P(D|h)P(h)</b>}{P(D)}$$
----------------------------------------
题目: 什么是极大后验假设（MAP）？
答案: 在给定数据 $D$ 时，假设空间 $H$ 中可能性最大（<b>后验概率最大</b>）的假设。<br>公式：$$h_{MAP} = \arg\max_{h \in H} P(D|h)P(h)$$
----------------------------------------
题目: 什么是极大似然假设（MLE）？
答案: 当假定 $H$ 中每个假设有<b>相同的先验概率</b>时，使 $P(D|h)$（<b>似然度</b>）最大的假设。<br>公式：$$h_{MLE} = \arg\max_{h \in H} P(D|h)$$
----------------------------------------
题目: 在什么条件下，极大后验假设（MAP）等同于极大似然假设（MLE）？
答案: 当假设空间 $H$ 中每个假设的<b>先验概率</b> $P(h)$ 相同时。
----------------------------------------
题目: 如果训练数据是无噪声的，且目标概念包含在假设空间中，那么与数据一致的假设对应哪种贝叶斯假设？
答案: 每个与数据一致的假设都是 <b>MAP</b>（极大后验） 假设。
----------------------------------------
题目: 如果训练值的误差服从均值为0的独立正态分布，那么最小化误差平方和等价于寻找什么？
答案: 等价于寻找<b>极大似然假设</b>（MLE）。
----------------------------------------
题目: 在神经网络中，使用梯度上升法最大化 $G(h,D)$ (对数似然) 对应于最小化什么误差函数？
答案: 对应于最小化<b>交叉熵</b>（Cross Entropy）。<br>注：这是基于观察到的布尔值为输入实例的概率函数的前提。
----------------------------------------
题目: 什么是最小描述长度（MDL）准则？
答案: 选择这样的假设：它使<b>假设的描述长度</b>和<b>给定假设下数据的描述长度</b>之和最小化。<br>公式：$$h_{MDL} = \arg\min_{h \in H} (L_{C_1}(h) + L_{C_2}(D|h))$$
----------------------------------------
题目: 贝叶斯最优分类器（Bayes Optimal Classifier）是如何进行分类的？
答案: 它将<b>所有假设</b>的预测结合起来，并用各假设的<b>后验概率</b>作为权重，计算新实例最可能的分类。<br>（注：它通常比任何单个假设的表现都要好，但计算开销大）。
----------------------------------------
题目: 什么是 Gibbs 算法？它的误差界限是多少？
答案: **定义**：按照后验概率分布从 $H$ 中<b>随机选择</b>一个假设 $h$ 来预测新实例。<br>**误差界限**：在一定条件下，其期望误分类率最多为贝叶斯最优分类器的<b>两倍</b>。
----------------------------------------
题目: 朴素贝叶斯分类器（Naive Bayes Classifier）的核心假设是什么？
答案: **条件独立**性假设：在给定目标值（类别）的情况下，各个属性值之间是相互独立的。
----------------------------------------
题目: 为什么朴素贝叶斯分类器要引入条件独立性假设？
答案: 为了解决<b>数据稀疏</b>问题（避免需要极大的训练集来估计联合概率），并降低计算复杂度。
----------------------------------------
题目: 朴素贝叶斯分类器中，为什么要使用 m-估计（m-estimate）？
答案: 为了解决<b>零概率</b>问题（当某个属性值在训练集中未出现时，会导致概率乘积为0）。<br>公式：$$P(w_k|v_j) = \frac{n_k + 1}{n + |Vocabulary|}$$ （以文本分类为例，均匀先验下）。
----------------------------------------
题目: 贝叶斯信念网（Bayesian Belief Networks）主要用于解决什么问题？
答案: 它提供了一种中间方法，比朴素贝叶斯的<b>完全独立</b>假设限制更少（允许定义变量子集间的条件独立性），又比全联合概率计算更可行。
----------------------------------------
题目: 在贝叶斯信念网中，网络中的节点和弧分别代表什么？
答案: **节点**：代表变量。<br>**弧**：代表断言“此变量在给定其直接前驱时<b>条件独立</b>于其非后继”。（即依赖关系）。
----------------------------------------
题目: 贝叶斯信念网的联合概率分布计算公式是什么？
答案: $$P(y_1, ..., y_n) = \prod_{i=1}^n P(y_i | \text{Parents}(y_i))$$
----------------------------------------
题目: 如果贝叶斯信念网的结构已知但部分变量不可观察，通常使用什么方法来学习条件概率表？
答案: <b>梯度上升</b>法（用于搜索极大似然假设）或者 <b>EM算法</b>（期望最大化）。
----------------------------------------
题目: 第五章总结：贝叶斯学习的主要知识点有哪些？
答案: 1. <b>基础</b>：贝叶斯公式，先验/后验概率，MAP与MLE的区别。<br>2. <b>分类器</b>：贝叶斯最优分类器（理论最优但昂贵），Gibbs算法（随机采样），朴素贝叶斯（属性独立假设，实战常用）。<br>3. <b>原理关联</b>：最小误差平方和对应高斯噪声下的MLE，最小描述长度（MDL）对应奥卡姆剃刀。<br>4. <b>扩展</b>：贝叶斯信念网（处理局部条件独立性）。
----------------------------------------


==================== 来自文件: data/问答题/6.json ====================

题目: 聚类的基本目标是什么？
答案: 将数据集中的样本划分为若干个通常不相交的子集（“簇”，cluster），使得<b>簇内相似度</b>高，且<b>簇间相似度</b>低。
----------------------------------------
题目: 聚类性能度量中的“外部指标”和“内部指标”有何区别？
答案: <b>外部指标</b> (External Index)：将聚类结果与某个<b>参考模型</b>（如已知的类标）进行比较。<br><b>内部指标</b> (Internal Index)：<b>直接考察</b>聚类结果而不用任何参考模型。
----------------------------------------
题目: 列举三个常见的聚类外部指标（External Indices）。
答案: 1. <b>Jaccard系数</b> (JC)<br>2. <b>FM指数</b> (FMI)<br>3. <b>Rand指数</b> (RI)<br>（注：这些指标在[0,1]区间内，值越大越好）
----------------------------------------
题目: DB指数 (DBI) 和 Dunn指数 (DI) 的评价标准是什么？
答案: <b>DBI</b>：<b>越小越好</b>（表示簇内距离小，簇间距离大）。<br><b>Dunn指数</b>：<b>越大越好</b>（表示簇间最小距离与簇内最大直径之比大）。
----------------------------------------
题目: 闵可夫斯基距离 (Minkowski distance) 中 p=1 和 p=2 分别对应什么距离？
答案: p=1：<b>曼哈顿距离</b> (Manhattan distance)<br>p=2：<b>欧氏距离</b> (Euclidean distance)
----------------------------------------
题目: 在距离计算中，如何处理“无序属性” (Non-ordinal attribute)？
答案: 可以使用 <b>VDM</b> (Value Difference Metric)。它基于属性值在各簇中出现的频率分布来计算两个离散值之间的距离。
----------------------------------------
题目: 原型聚类 (Prototype-based clustering) 的核心假设是什么？
答案: 假设聚类结构能通过<b>一组原型</b>刻画。通常先对原型初始化，再进行迭代更新求解。
----------------------------------------
题目: k均值 (k-Means) 算法的优化目标是什么？
答案: <b>最小化平方误差</b> E，即簇内样本围绕簇均值向量的紧密程度。E值越小，簇内样本相似度越高。
----------------------------------------
题目: LVQ (学习向量量化) 算法与一般聚类算法最大的不同是什么？
答案: LVQ 假设数据样本带有<b>类别标记</b>（监督信息），利用这些监督信息来辅助学习一组原型向量。
----------------------------------------
题目: EM 算法 (Expectation-Maximization) 的两个主要步骤是什么？
答案: <b>E步</b> (Expectation)：以当前参数推断隐变量的分布（计算<b>期望</b>）。<br><b>M步</b> (Maximization)：寻找能<b>最大化</b>期望似然的参数。
----------------------------------------
题目: 高斯混合聚类 (GMM) 采用什么模型来表达聚类原型？
答案: 采用<b>概率模型</b>（多元高斯分布）。它假设样本由 k 个混合的<b>高斯分布</b>生成，每个成分对应一个簇。
----------------------------------------
题目: DBSCAN 算法基于哪两个参数来刻画样本分布的紧密程度？
答案: 1. <b>ϵ</b> (epsilon)：邻域半径<br>2. <b>MinPts</b>：邻域内包含的最小样本数
----------------------------------------
题目: 在 DBSCAN 中，什么是“核心对象”？
答案: 若某个样本的 ϵ-邻域内<b>至少包含 MinPts 个样本</b>，则该样本点为一个核心对象。
----------------------------------------
题目: 相比于 k-Means，DBSCAN 算法的主要优势是什么？
答案: 1. 可以发现<b>任意形状</b>的簇（不仅仅是球形）。<br>2. 对<b>噪声</b>（异常点）不敏感。<br>3. 不需要预先指定簇的个数 k。
----------------------------------------
题目: AGNES 算法采用的是什么样的层次聚类策略？
答案: <b>自底向上</b> (Bottom-up) 的聚合策略。起初将每个样本看作一个簇，然后不断合并距离最近的两个簇。
----------------------------------------
题目: AGNES 算法中，计算两个簇之间距离的常用方法有哪些？
答案: 1. <b>最小距离</b> (Single Linkage)<br>2. <b>最大距离</b> (Complete Linkage)<br>3. <b>平均距离</b> (Average Linkage)
----------------------------------------
题目: 为什么数据预处理中的“归一化” (Normalization) 对聚类很重要？
答案: 因为聚类通常依赖<b>距离计算</b>。如果特征的<b>尺度</b>（Scale）差异很大，数值范围大的特征会主导距离计算，导致聚类结果偏差。
----------------------------------------
题目: 本章小结：请总结 k-Means、DBSCAN 和 AGNES 的分类体系。
答案: 1. <b>k-Means</b>：<b>原型聚类</b>（基于均值向量，需预设k，适合球状簇）。<br>2. <b>DBSCAN</b>：<b>密度聚类</b>（基于样本密度连接性，抗噪，适合任意形状）。<br>3. <b>AGNES</b>：<b>层次聚类</b>（自底向上构建树状结构）。
----------------------------------------


==================== 来自文件: data/问答题/7.json ====================

题目: 强化学习 (RL) 与监督学习的主要区别是什么？
答案: 1. <b>输入数据</b>：RL是<b>序列数据</b>（相互关联），监督学习通常是独立同分布数据。<br>2. <b>反馈机制</b>：RL只有<b>奖励信号</b>（标量），没有告诉智能体正确动作的标签。<br>3. <b>目标</b>：RL最大化<b>长期累积收益</b>，监督学习最小化预测误差。<br>4. <b>过程</b>：RL包含<b>探索与开发</b> (Exploration & Exploitation) 的平衡。
----------------------------------------
题目: 马尔可夫决策过程 (MDP) 的五元组通常包含哪些要素？
答案: $\langle S, A, P, R, \gamma \rangle$<br>S: <b>状态</b>空间<br>A: <b>动作</b>空间<br>P: <b>状态转移概率</b><br>R: <b>奖励函数</b><br>$\gamma$: <b>衰减因子</b> (Discount factor)
----------------------------------------
题目: 在 MDP 中，什么是“马尔可夫性” (Markov Property)？
答案: 指未来的状态只取决于<b>当前的状态和动作</b>，而与过去的历史状态和动作<b>无关</b>。<br>即：$P(s_{t+1} | s_t, a_t, ...) = P(s_{t+1} | s_t, a_t)$
----------------------------------------
题目: 强化学习中衰减因子 $\gamma$ (Gamma) 的作用是什么？
答案: 1. 数学上：避免无限时间步长的累积奖励发散（使级数<b>收敛</b>）。<br>2. 物理意义：决定智能体的“<b>远见</b>”。$\gamma=0$ 表示只关注即时奖励（短视），$\gamma$接近1 表示重视未来长期回报。
----------------------------------------
题目: 状态价值函数 $V_\pi(s)$ 与 动作价值函数 $Q_\pi(s, a)$ 的定义区别？
答案: <b>$V_\pi(s)$</b>：从<b>状态 s</b> 开始，遵循策略 $\pi$ 能获得的预期回报。<br><b>$Q_\pi(s, a)$</b>：从状态 s 开始，执行<b>动作 a</b>，此后遵循策略 $\pi$ 能获得的预期回报。
----------------------------------------
题目: 贝尔曼方程 (Bellman Equation) 描述了什么关系？
答案: 描述了<b>当前状态价值</b>与<b>后继状态价值</b>之间的<b>递归</b>关系。<br>例如：$V(s) = R + \gamma \sum P(s'|s,a) V(s')$
----------------------------------------
题目: 动态规划 (Dynamic Planning) 方法求解 RL 问题的最大局限性是什么？
答案: 需要知道完备的环境知识（即<b>模型已知</b>，已知状态转移概率 P 和奖励函数 R），这在实际问题中很难满足。
----------------------------------------
题目: 蒙特卡洛方法 (Monte Carlo, MC) 的核心思想是什么？
答案: 1. <b>无模型</b> (Model-free)：不需要环境的状态转移模型。<br>2. <b>基于经验</b>：通过与环境交互产生<b>完整的轨迹</b> (Episode)。<br>3. <b>更新方式</b>：利用完整轨迹的<b>平均回报</b>来估计价值函数（通常用于分幕式任务）。
----------------------------------------
题目: 时序差分学习 (TD Learning) 相比于蒙特卡洛方法 (MC) 有什么优势？
答案: 1. <b>在线学习</b>：不需要等到回合结束，可以<b>单步更新</b>（Bootstrapping，自举）。<br>2. <b>适用性</b>：可用于<b>连续任务</b>（非分幕式）。<br>3. <b>方差</b>：通常比 MC <b>方差更低</b>，但因自举引入了偏差。
----------------------------------------
题目: SARSA 算法的更新公式是怎样的？它是 On-policy 还是 Off-policy？
答案: 公式：$Q(s, a) \leftarrow Q(s, a) + \alpha[R + \gamma Q(s', a') - Q(s, a)]$<br>类型：<b>On-policy</b> (同策略)。因为它更新时使用的是<b>实际执行</b>的下一个动作 $a'$。
----------------------------------------
题目: Q-Learning 算法的更新公式是怎样的？它是 On-policy 还是 Off-policy？
答案: 公式：$Q(s, a) \leftarrow Q(s, a) + \alpha[R + \gamma \max Q(s', a') - Q(s, a)]$<br>类型：<b>Off-policy</b> (异策略)。因为它更新时假设下一步采取的是<b>最优动作</b> (max)，而实际行为可能包含探索 (如 $\epsilon$-greedy)。
----------------------------------------
题目: 解释 On-policy (同策略) 与 Off-policy (异策略) 的区别。
答案: <b>On-policy</b>：采样（行为）策略与待优化（目标）策略是<b>同一个</b>。<br><b>Off-policy</b>：采样（行为）策略与待优化（目标）策略是<b>不同</b>的（例如用随机策略收集数据来优化贪婪策略）。
----------------------------------------
题目: 表格型 (Tabular) 强化学习方法（如 Q-table）的主要缺点是什么？
答案: 1. <b>存储限制</b>：无法处理<b>高维</b>或连续的状态空间（<b>状态爆炸</b>）。<br>2. <b>泛化能力差</b>：无法从已学习的状态推演到未见过的状态。
----------------------------------------
题目: DQN (Deep Q-Network) 引入了哪两个关键技术来解决深度强化学习训练不稳定的问题？
答案: 1. <b>经验回放</b> (Experience Replay)：解决样本间的相关性问题。<br>2. <b>固定 Q 目标</b> (Fixed Q-targets)：解决目标值非平稳的问题。
----------------------------------------
题目: 在 DQN 中，经验回放 (Experience Replay) 的具体做法是什么？
答案: 将智能体与环境交互产生的转移样本 $(s, a, r, s')$ 存入一个<b>回放内存</b> (Replay Buffer) 中，训练时从内存中<b>随机采样</b>一个小批量 (Mini-batch) 进行梯度下降更新。
----------------------------------------
题目: 本章小结：请总结策略迭代、蒙特卡洛、TD、SARSA、Q-Learning 的分类特点。
答案: 1. <b>策略/价值迭代</b>：基于动态规划，<b>模型已知</b>。<br>2. <b>蒙特卡洛 (MC)</b>：无模型，需<b>完整轨迹</b>。<br>3. <b>时序差分 (TD)</b>：无模型，结合 DP 和 MC，支持<b>在线学习</b>。<br>4. <b>SARSA</b>：<b>On-policy</b> 的 TD 控制。<br>5. <b>Q-Learning</b>：<b>Off-policy</b> 的 TD 控制。<br>6. <b>DQN</b>：<b>神经网络</b>拟合 Q 值，解决高维空间问题。
----------------------------------------


==================== 来自文件: data/问答题/8.json ====================

题目: 评估学习算法精度时，面临的两个关键困难是什么？
答案: 1. <b>估计的困难（偏差）</b>：如何使用有限的数据得出对未来数据的准确估计。<br>2. <b>估计的方差</b>：即使是无偏估计，不同的测试集也可能导致不同的结果（数据越少，方差越大）。
----------------------------------------
题目: 样本错误率 (Sample Error, $error_S(h)$) 的定义是什么？
答案: 假设 $h$ 在样本集合 $S$ 上错误分类的样本比例。<br>公式：$error_S(h) = \frac{1}{n} \sum_{x \in S} <b>\delta(f(x), h(x))</b>$<br>其中 $\delta$ 当预测错误时为1，否则为0。
----------------------------------------
题目: 真实错误率 (True Error, $error_D(h)$) 的定义是什么？
答案: 假设 $h$ 在<b>整个概率分布</b> $D$ 上错误分类实例的<b>概率</b>。<br>公式：$error_D(h) = Pr_{x \in D}[f(x) \neq h(x)]$。
----------------------------------------
题目: 对于离散值假设，真实错误率 $error_D(h)$ 的 N% 置信区间近似公式是什么？
答案: $$error_S(h) \pm <b>z_N</b> \sqrt{\frac{error_S(h)(1-error_S(h))}{n}}$$ <br> 其中 $n$ 是样本大小，$z_N$ 是<b>置信度常数</b>（如95%对应1.96）。
----------------------------------------
题目: 使用正态分布近似计算二项分布的置信区间时，需要满足什么条件？
答案: 1. 样本量 $n \ge <b>30</b>$。<br>2. $n \cdot error_S(h) \cdot (1 - error_S(h)) \ge <b>5</b>$ (即错误率不太靠近0或1)。
----------------------------------------
题目: 什么是估计量的“偏差” (Bias)？
答案: 估计量的<b>期望值</b>与<b>真实参数值</b>之间的差：$Bias = E[Y] - p$。<br>如果偏差为0，则称 $Y$ 为 $p$ 的<b>无偏估计量</b>。
----------------------------------------
题目: 为什么说样本错误率 $error_S(h)$ 是真实错误率 $error_D(h)$ 的无偏估计量？
答案: 因为 $error_S(h)$ 服从<b>二项分布</b>，其<b>期望值</b> $E[error_S(h)] = p = error_D(h)$。<br>前提是数据是<b>独立同分布</b>抽取的。
----------------------------------------
题目: 中心极限定理 (Central Limit Theorem) 的核心含义是什么？
答案: 当样本量 $n \to \infty$ 时，独立同分布随机变量的<b>样本均值</b>所服从的分布趋近于<b>正态分布</b>，无论原始变量服从什么分布。
----------------------------------------
题目: 比较两个假设 $h_1$ 和 $h_2$ 的错误率差异 $d$ 时，差异的方差 $\sigma_d^2$ 如何计算（假设使用独立样本）？
答案: 是两个独立正态分布的<b>方差之和</b>：<br>$$\sigma_d^2 \approx \frac{error_{S_1}(h_1)(1-error_{S_1}(h_1))}{n_1} + \frac{error_{S_2}(h_2)(1-error_{S_2}(h_2))}{n_2}$$
----------------------------------------
题目: 双侧置信区间与单侧置信区间的置信度有何关系？
答案: 正态分布是<b>对称</b>的。一个 $100(1-\alpha)\%$ 的双侧置信区间的上界（或下界），对应于一个 <b>100(1-\alpha/2)%</b> 的单侧置信区间。<br>例如：90%的双侧区间对应95%的单侧区间。
----------------------------------------
题目: 比较两个学习算法（而非特定假设）时，通常采用什么方法？
答案: <b>k-Fold 交叉验证</b> (Cross Validation)。<br>将数据分为 $k$ 份，进行 $k$ 次训练和测试，计算错误率差值的<b>平均值</b> $\bar{\delta}$。
----------------------------------------
题目: 在 k-Fold 交叉验证中，计算置信区间为何使用 t分布 而不是 正态分布？
答案: 因为我们通常不知道真实的样本标准差，只能用<b>样本标准差</b> $s_{\delta}$ 进行估计。当样本量较小时，<b>t分布</b>（更宽更矮）能更好地反映这种不确定性。
----------------------------------------
题目: 配对 t-测试 (Paired t-test) 的自由度是多少？
答案: 自由度 $v = <b>k - 1</b>$，其中 $k$ 是测试的次数（例如 k-fold 中的 k）。
----------------------------------------
题目: 在实际应用中，k-Fold 交叉验证是否完全满足统计学独立性假设？为什么？
答案: <b>不完全满足</b>。<br>因为不同的训练集之间存在<b>重叠</b>（共享了部分数据），导致生成的假设不完全独立。但它仍提供了良好的近似。
----------------------------------------
题目: 本章小结：算法评估的核心逻辑是什么？
答案: 1. 利用<b>统计学</b>方法，用有限样本上的观察精度逼近真实精度。<br>2. 识别<b>估计偏差</b>（期望与真值的差）和<b>估计方差</b>（估计值的波动）。<br>3. 使用<b>置信区间</b>来量化不确定性。<br>4. 使用<b>t-测试</b>等假设检验方法来比较不同算法的性能差异。
----------------------------------------


==================== 来自文件: data/问答题/9.json ====================

题目: 人工智能中“问题求解”的五个形式化组成部分是什么？
答案: 1. <b>初始状态</b> (Initial State)<br>2. <b>可能行动</b> (Actions)<br>3. <b>转移模型</b> (Transition Model)<br>4. <b>目标测试</b> (Goal Test)<br>5. <b>路径耗散</b>函数 (Path Cost)
----------------------------------------
题目: 在搜索算法中，OPEN表（Frontier）和CLOSED表（Explored Set）分别有什么作用？
答案: <b>OPEN表</b>：存放<b>已生成但未被扩展</b>的节点（待考察）。<br><b>CLOSED表</b>：存放<b>已经扩展过</b>的节点（已考察），用于<b>避免重复搜索</b>。
----------------------------------------
题目: 广度优先搜索 (BFS) 和深度优先搜索 (DFS) 在扩展策略和数据结构上有什么区别？
答案: 1. <b>BFS</b>：一层层扩展（FIFO），使用<b>队列</b> (Queue)。<br>2. <b>DFS</b>：尽可能深地扩展（LIFO），使用<b>栈</b> (Stack)。
----------------------------------------
题目: 什么是一致代价搜索 (Uniform-cost Search, UCS)？它在什么情况下是最优的？
答案: UCS 总是扩展<b>路径消耗 g(n)</b> 最低的节点。<br>它是广度优先搜索的引申，当每一步代价不相等时，UCS 是<b>最优</b>的（完备且最优）。
----------------------------------------
题目: 贪婪最好优先搜索 (Greedy Best-First Search) 的评价函数是什么？它的主要缺点是什么？
答案: 评价函数：<b>f(n) = h(n)</b>（仅考虑当前节点到目标的<b>估计距离</b>）。<br>缺点：<b>不完备</b>（可能陷入死循环）、<b>非最优</b>（只看眼前，可能走远路）。
----------------------------------------
题目: A* 搜索算法的评价函数是什么？其中各项代表什么？
答案: <b>f(n) = g(n) + h(n)</b><br>g(n)：从初始节点到节点 n 的<b>实际</b>路径耗散。<br>h(n)：从节点 n 到目标节点的<b>估计</b>最小耗散（启发式）。
----------------------------------------
题目: 在 A* 算法中，什么是“可容许的 (Admissible)”启发式函数？
答案: 指 h(n) <b>从不高估</b>到达目标的最低路径耗散。<br>即：$h(n) \le h^*(n)$（其中 $h^*$ 是真实代价）。<br>如果是树搜索，h 可容许则 A* <b>最优</b>。
----------------------------------------
题目: 曼哈顿距离 (Manhattan Distance) 和欧氏距离 (Euclidean Distance) 有什么区别？
答案: <b>曼哈顿距离</b>：两点在标准坐标系上的<b>绝对轴距总和</b>（$|x_1-x_2| + |y_1-y_2|$），常用于网格移动。<br><b>欧氏距离</b>：两点间的<b>直线距离</b>（$\sqrt{(x_1-x_2)^2 + (y_1-y_2)^2}$）。
----------------------------------------
题目: 迭代深入 A* (IDA*) 算法相对于普通 A* 算法的主要优势是什么？
答案: IDA* 结合了迭代加深和 A* 的思想，使用 <b>f-cost</b> 作为截断值。<br>优势：<b>空间复杂度低</b>（<b>线性空间</b> $O(bd)$），避免了 A* 需要指数级内存来存储所有节点的问题。
----------------------------------------
题目: 局部搜索算法（如爬山法）通常适用于哪类问题？
答案: 适用于<b>关注解状态本身</b>（最终状态），而<b>不关心到达解的路径</b>（路径代价）的优化问题（如八皇后、TSP）。
----------------------------------------
题目: 爬山法 (Hill-climbing) 的主要缺陷有哪些？
答案: 1. <b>局部最优</b> (Local Maxima)：困在比周围高但不是最高的地方。<br>2. <b>高原</b> (Plateaus)：平坦区域，无法确定方向。<br>3. <b>山脊</b> (Ridges)：看似无法上升但其实可以沿着山脊走。
----------------------------------------
题目: 模拟退火算法 (Simulated Annealing) 如何避免陷入局部最优？
答案: 通过允许以一定的<b>概率接受“坏”的移动</b>（即向低处走）。<br>接受概率由<b>温度 T</b> 控制，随着时间推移 T 逐渐降低，接受坏移动的概率也随之降低。
----------------------------------------
题目: 遗传算法 (Genetic Algorithm) 的四个基本算子（操作）是什么？
答案: 1. <b>选择</b> (Selection)：优胜劣汰。<br>2. <b>交叉</b>/杂交 (Crossover)：父代片段重组。<br>3. <b>变异</b> (Mutation)：随机改变基因。<br>4. <b>复制</b> (Replication)：直接遗传给下一代。
----------------------------------------
题目: 比较 h1 (错位棋子数) 和 h2 (曼哈顿距离) 在八数码问题中的优劣。
答案: <b>h2 优于 h1</b>。<br>因为对于所有节点 n，有 $h_2(n) \ge h_1(n)$，且两者都是可容许的。h2 更接近真实代价，能显著减少 A* 算法<b>扩展的节点数</b>。
----------------------------------------
题目: 本章小结：请总结无信息搜索、启发式搜索和局部搜索的核心算法。
答案: 1. <b>无信息搜索</b>：BFS（广度优先）、DFS（深度优先）、UCS（一致代价）、IDS（迭代加深）。<br>2. <b>启发式搜索</b>：贪婪最好优先（f=h）、A*（f=g+h，最优需h可容许）、IDA*（节省空间）。<br>3. <b>局部搜索</b>：爬山法（贪婪，易陷局部最优）、模拟退火（概率接受劣解）、遗传算法（进化论思想）。
----------------------------------------


==================== 来自文件: data/问答题/10.json ====================

题目: 实时搜索 (Real-Time Search) 的核心约束是什么？
答案: 在有限的时间内（通常是极短的延迟）做出搜索与决策，需要在<b>解的质量</b>与<b>计算时间</b>之间进行权衡。
----------------------------------------
题目: RTA* (Real-Time A*) 算法与传统 A* 算法的主要区别是什么？
答案: 1. <b>局部搜索</b>：RTA* 每次仅向前搜索有限深度（局部视界），而不是遍历全图。<br>2. <b>决策依据</b>：根据 $f(n)=g(n)+h(n)$ 选择局部最优的邻居作为下一步。<br>3. <b>次优记忆</b>：记录当前节点的“次优 $f$ 值”以避免死循环（回溯）。
----------------------------------------
题目: 在 RTA* 算法中，为什么需要记录“次优 f 值” (Second-best f-value)？
答案: 为了在遇到死胡同或局部陷阱时，能够更新当前节点的估值（使其变大），从而引导智能体<b>回溯</b>并探索其他路径，避免在<b>局部循环</b>。
----------------------------------------
题目: LRTA* (Learning Real-Time A*) 算法中的“学习”指的是什么？
答案: 指通过在每次移动后更新已访问状态的<b>启发式值</b> (Heuristic Value)，使其逐渐逼近真实代价，从而在重复任务中收敛到最优解。
----------------------------------------
题目: 迭代加深搜索 (IDS/IDDFS) 结合了哪两种基础搜索算法的优点？
答案: 结合了 <b>DFS</b> (深度优先搜索) 的空间效率（线性空间复杂度）和 <b>BFS</b> (广度优先搜索) 的完备性与最优性。
----------------------------------------
题目: IDA* (Iterative Deepening A*) 算法中的截断阈值是什么？
答案: 截断值是 <b>f 代价</b> ($f(n) = g(n) + h(n)$)，而不是搜索深度。当节点的 $f$ 值超过当前阈值时停止扩展。
----------------------------------------
题目: 增量式搜索 (Incremental Search) 的核心理念是什么？
答案: 针对随时间动态变化的问题，<b>复用</b>先前的计算结果，仅对发生变化的部分进行<b>局部更新</b>，而不是每次从头重新计算。
----------------------------------------
题目: D* Lite 算法主要适用于什么场景？与 A* 相比有何优势？
答案: <b>场景</b>：<b>动态环境</b>下的路径规划（如未知地图导航、移动障碍物）。<br><b>优势</b>：当环境变化（边权重改变）时，D* Lite 仅<b>增量修复</b>受影响的路径部分，而 A* 通常需要从头重算，D* Lite 效率更高。
----------------------------------------
题目: 在 D* Lite 算法中，$g$ 值和 $rhs$ 值分别代表什么？
答案: <b>$g$ 值</b>：当前节点到目标点的已知（旧的）最短路径代价。<br><b>$rhs$ 值</b>：基于邻居节点计算出的“<b>一步前瞻</b>”代价（Lookahead value）。<br>当 $g \neq rhs$ 时，表示状态<b>不一致</b>，需要更新。
----------------------------------------
题目: Anytime Dynamic A* (AD*) 算法如何平衡搜索速度与路径质量？
答案: 通过引入<b>膨胀因子</b> $\epsilon \ge 1$。先快速找到一个不超 $\epsilon$ 倍最优代价的可行解（<b>次优解</b>），利用剩余时间逐步减小 $\epsilon$，优化路径逼近最优解。
----------------------------------------
题目: 动态规划 (Dynamic Programming) 能够高效求解问题的两个必要条件是什么？
答案: 1. <b>最优子结构</b> (Optimal Substructure)：整体最优解包含子问题的最优解。<br>2. <b>重叠子问题</b> (Overlapping Subproblems)：子问题在求解过程中被反复计算（可缓存复用）。
----------------------------------------
题目: 领域知识 (Domain Knowledge) 如何帮助优化搜索过程？
答案: 1. <b>剪枝</b>：利用规则或约束提前排除无效路径，缩小搜索空间。<br>2. <b>改进启发式</b>：设计更准确的 $h(n)$ 函数，引导搜索方向。<br>3. <b>约束传播</b>：通过逻辑推理减少变量的取值范围。
----------------------------------------
题目: 约束满足问题 (CSP) 由哪三个部分组成？
答案: 1. <b>变量</b>集 (Variables)<br>2. <b>值域</b> (Domains)<br>3. <b>约束</b>集 (Constraints)
----------------------------------------
题目: AlphaZero 算法的核心架构是如何结合搜索与学习的？
答案: 它结合了 <b>蒙特卡洛树搜索</b> (MCTS) 和 <b>深度神经网络</b>。<br>神经网络提供策略头（Policy）指导 MCTS 选择走法，以及价值头（Value）评估状态，MCTS 的结果反过来用于训练神经网络（自我对弈）。
----------------------------------------
题目: 什么是神经启发式搜索 (Neural Heuristic Search)？
答案: 利用<b>深度学习</b>（神经网络）从大量数据中自动学习<b>启发式函数</b>，用来替代人工设计的启发式，以在复杂高维状态空间中引导搜索算法（如 A*）。
----------------------------------------
题目: 本章小结：实时搜索、增量搜索与知识驱动搜索的主要目标分别是什么？
答案: 1. <b>实时搜索</b>：在严格时间限制下给出可行解。<br>2. <b>增量搜索</b>：在动态环境中<b>复用</b>计算，快速重规划。<br>3. <b>知识驱动搜索</b>：利用领域知识、逻辑或学习模型来剪枝和引导搜索，解决复杂问题。
----------------------------------------


==================== 来自文件: data/问答题/11.json ====================

题目: 智能体 (Agent) 的核心定义公式是什么？
答案: f: P* -> A<br><br>即：从<b>感知序列</b>到<b>动作</b>的映射函数。
----------------------------------------
题目: 智能体 (Agent) 的四大核心特性是什么？
答案: 1. <b>自主性</b> (Autonomy)：无人工干预，自我控制。<br>2. <b>交互性</b> (Social Ability)：与环境/其他Agent通信。<br>3. <b>反应性</b> (Reactivity)：感知环境并及时响应。<br>4. <b>适应性</b> (Adaptability)：根据环境变化调整目标/计划。
----------------------------------------
题目: 智能体 vs 普通程序 的主要区别？ (PPT对比维度)
答案: 1. <b>自主性</b>：智能体自主决策 vs 程序依赖人工触发。<br>2. <b>交互性</b>：双向动态交互 vs 单一人机交互。<br>3. <b>适应性</b>：灵活调整策略 vs 逻辑固定。<br>4. <b>目标导向</b>：动态调整步骤达标 vs 执行单一指令。
----------------------------------------
题目: 四种基本智能体结构类型分别是什么？
答案: 1. <b>简单反射型</b> (Simple Reflex)<br>2. <b>基于模型的反射型</b> (Model-based Reflex)<br>3. <b>基于目标型</b> (Goal-based)<br>4. <b>基于效用型</b> (Utility-based)
----------------------------------------
题目: 简单反射型智能体 (Simple Reflex) 的特点和局限？
答案: <b>特点</b>：基于<b>当前感知</b>选择行动 (If-Then 规则)。<br><b>局限</b>：忽略感知历史，仅适用于<b>环境完全可观</b>的情况。
----------------------------------------
题目: 基于模型的反射型智能体 引入了什么核心组件？解决什么问题？
答案: 引入了<b>世界模型</b> (World Model/Internal State)。<br>记录了：<br>1. 世界如何演变。<br>2. 动作如何影响世界。<br><b>解决问题</b>：环境部分可观 (Partial Observability)。
----------------------------------------
题目: 基于目标型 (Goal-based) vs 基于效用型 (Utility-based) 的核心区别？
答案: <b>基于目标型</b>：二元判断（达成/未达成），有明确终点。<br><b>基于效用型</b>：使用<b>效用函数 (Utility Function)</b> 映射到实数，衡量“高兴程度”（效率/成本/收益），用于在<b>目标冲突</b>或<b>不确定</b>结果中做<b>最优</b>决策。
----------------------------------------
题目: 学习智能体 (Learning Agent) 的四个主要组件？
答案: 1. <b>学习元件</b> (Learning Element)：负责改进。<br>2. <b>执行元件</b> (Performance Element)：负责选择动作。<br>3. <b>评论元件</b> (Critic)：提供反馈/评价。<br>4. <b>问题产生器</b> (Problem Generator)：提议探索性行动。
----------------------------------------
题目: 多智能体系统 (MAS) 的三种协作类型？
答案: 1. <b>合作</b> (Cooperation)：为了共同目标。<br>2. <b>竞争</b> (Competition)：目标冲突，零和博弈。<br>3. <b>竞合</b> (Coopetition)：部分协作，部分竞争（如谈判）。
----------------------------------------
题目: 马尔可夫决策过程 (MDP) 的四个要素是什么？
答案: <b>S, A, P, R</b><br>1. <b>S (State)</b>：状态空间<br>2. <b>A (Action)</b>：动作空间<br>3. <b>P (Probability)</b>：状态转移概率<br>4. <b>R (Reward)</b>：奖励函数
----------------------------------------
题目: 为什么 LLM 适合作为智能体的“大脑”？(4点)
答案: 1. <b>自主性</b>：直接集成无需人工。<br>2. <b>反应性</b>：对环境刺激快速反应。<br>3. <b>积极主动性</b>：具备推理和规划能力。<br>4. <b>社交能力</b>：理解人类语言交互。
----------------------------------------
题目: AI发展的四个时代 (PPT第40页)？
答案: 1. <b>符号规则时代</b> (1950s-80s)：人工编写规则。<br>2. <b>统计学习时代</b> (1990s-2010s)：概率预测 (SVM等)。<br>3. <b>深度学习时代</b> (2012-2020)：端到端感知 (CNN/RNN)。<br>4. <b>大模型驱动时代</b> (2020-今)：CoT推理，通用任务拆解。
----------------------------------------
题目: LLM Agent 经典框架的三大模块？
答案: 1. <b>大脑 (Brain)</b>：知识、记忆、推理、规划。<br>2. <b>感知 (Perception)</b>：多模态输入处理。<br>3. <b>行动 (Action)</b>：工具使用、具身行动。
----------------------------------------
题目: AutoGPT 的三个核心特性？
答案: 1. <b>自主迭代</b>：从错误中学习，循环执行。<br>2. <b>内存管理</b>：集成矢量数据库 (Vector DB) 保存长期记忆。<br>3. <b>多功能性</b>：文件操作、网页浏览等。
----------------------------------------
题目: LangChain 的核心价值和两个主要模块？
答案: <b>核心价值</b>：基于LLM的应用开发框架，提供抽象层。<br><b>模块</b>：<br>1. <b>Components (组件)</b>：LLM包装器、提示词模板等。<br>2. <b>Chains (链)</b>：将组件组合以完成高级任务。
----------------------------------------
题目: ReAct 框架的核心思想是什么？
答案: <b>Reasoning (推理) + Acting (行动)</b>。<br>将思考步骤（Think）和行动步骤（Act）交替进行，推理指导行动，行动反馈更新推理。
----------------------------------------
题目: 任务规划 (Task Planning) 中“任务分解”的两种主要方法？
答案: 1. <b>分解优先 (Decomposition-First)</b>：先将任务全部分解为子目标，再依次执行。<br>2. <b>交错分解 (Interleaved Decomposition)</b>：一边分解一边执行，根据当前状态动态调整。
----------------------------------------
题目: 分解优先 (Decomposition-First) 的优缺点？
答案: <b>优点</b>：子任务联系强，全局观好。<br><b>缺点</b>：容错率低，一步错步步错 (Cascade error)。<br><b>案例</b>：HuggingGPT, Plan-and-Solve。
----------------------------------------
题目: 交错分解 (Interleaved Decomposition) 的优缺点？
答案: <b>优点</b>：容错性高，适应环境反馈。<br><b>缺点</b>：复杂任务容易偏离原始目标，受限于上下文长度（遗忘）。<br><b>案例</b>：ReAct, CoT。
----------------------------------------
题目: CoT (思维链) 的核心指令是什么？作用是什么？
答案: <b>指令</b>：Let's think step by step。<br><b>作用</b>：诱导模型生成中间推理步骤，利用更多计算量将复杂问题拆解，提升推理性能。
----------------------------------------
题目: 多计划选择 (Multi-Plan Selection) 的流程？
答案: 1. <b>生成</b>：LLM 生成多种可能的解决方案。<br>2. <b>选择</b>：Agent (或评估器) 从中选择最优的一个执行。<br><b>目的</b>：解决LLM生成的随机性和非最优问题。
----------------------------------------
题目: 自我反思 (Self-Reflection) 的常见机制有哪些？
答案: 1. <b>Self-Refine</b>：生成计划后自我反馈并调整。<br>2. <b>Reflexion</b>：通过评估器检测错误并生成反思文本（保存到记忆）。<br>3. <b>CRITIC</b>：利用<b>外部工具</b>（如搜素引擎）验证事实准确性。
----------------------------------------
题目: LLM Agent 的记忆增强主要有哪两种方式？
答案: 1. <b>RAG (检索增强生成)</b>：外挂数据库，检索历史经验（非参数化）。<br>2. <b>参数记忆 (Parametric Memory)</b>：通过微调 (Fine-tuning) 将经验嵌入模型参数。
----------------------------------------
题目: 外部规划器分为哪两类？
答案: 1. <b>符号规划器</b>：基于形式化逻辑 (PDDL)，如 LLM+P。<br>2. <b>神经规划器</b>：基于深度学习模型，如 DRRN。
----------------------------------------
题目: 当前 Agent 面临的四大核心挑战 (PPT第53页)？
答案: 1. <b>认知与推理局限</b>：幻觉、思维循环。<br>2. <b>具身交互复杂性</b>：硬件限制、环境噪声。<br>3. <b>自主进化瓶颈</b>：难以像人类一样试错积累经验。<br>4. <b>安全性与伦理</b>：不可控行为、数据隐私。
----------------------------------------


==================== 来自文件: data/问答题/12.json ====================

题目: 什么是对抗搜索 (Adversarial Search)？
答案: 指在<b>竞争环境</b>中，多个<b>智能体</b>（Agent）之间的目标是有<b>冲突</b>的（如博弈游戏），智能体需要根据当前局势选择对自己最有利的行动的搜索问题。
----------------------------------------
题目: 在博弈论中，什么是纳什均衡 (Nash Equilibrium)？
答案: 指博弈中这样一种<b>稳定的状态</b>：如果任意一位参与者在其他所有参与者的策略确定的情况下，其选择的策略是<b>最优</b>的（即没有人愿意<b>单方面改变</b>自己的策略），那么这个组合就被定义为纳什均衡。
----------------------------------------
题目: 极大极小算法 (Minimax Algorithm) 的核心假设是什么？
答案: 假设对手是<b>完全理性</b>的，即对手每一步都会做出对其最有利（对你最不利）的选择（"料敌先机"）。
----------------------------------------
题目: 在极大极小算法中，MAX节点和MIN节点分别如何选择回传值？
答案: <b>MAX节点</b>：选择子节点中的<b>最大值</b>（目标是最大化自己的收益）。<br><b>MIN节点</b>：选择子节点中的<b>最小值</b>（目标是最小化对手的收益）。
----------------------------------------
题目: $\alpha-\beta$ 剪枝算法的主要作用和特点是什么？
答案: <b>作用</b>：是极大极小算法的<b>优化</b>，通过<b>剪去</b>不必要的搜索分支来提高效率。<br><b>特点</b>：它产生的结果与 Minimax <b>完全相同</b>，但运行效率更高。
----------------------------------------
题目: 在 $\alpha-\beta$ 剪枝中，$\alpha$ 和 $\beta$ 分别代表什么含义？
答案: <b>$\alpha$</b>：到目前为止路径上发现的 <b>MAX</b> 的最佳选择（下界，极大值）。<br><b>$\beta$</b>：到目前为止路径上发现的 <b>MIN</b> 的最佳选择（上界，极小值）。
----------------------------------------
题目: $\alpha-\beta$ 剪枝发生的条件是什么？
答案: 当 <b>$\alpha \ge \beta$</b> 时，该节点剩余的分支就不必继续搜索了（发生剪枝）。
----------------------------------------
题目: 在资源受限（如时间有限）的情况下，如何改进完全的极大极小搜索？
答案: 使用<b>截断搜索</b> (Cutoff Search)：<br>1. 用<b>启发式评估函数</b> (Evaluation Function) 代替效用函数。<br>2. 用<b>截断测试</b>（如深度限制）取代终止测试。
----------------------------------------
题目: 常用的线性加权评估函数的形式是怎样的？
答案: $$Eval(s) = \sum_{i=1}^{n} w_i f_i(s)$$<br>其中 $w_i$ 是<b>权值</b>，$f_i(s)$ 是棋局的某个<b>特征</b>（如棋子数量、价值等）。
----------------------------------------
题目: 什么是“水平线效应” (Horizon Effect)？
答案: 指由于搜索<b>深度有限</b>，AI 无法看到截断点（“水平线”）之后即将发生的<b>灾难性后果</b>（如丢子），从而做出误判。
----------------------------------------
题目: 为了缓解水平线效应，通常采用什么技术？
答案: <b>静止搜索</b> (Quiescence Search)：在到达预设深度时，如果局面处于“<b>动荡</b>”状态（如吃子、将军），则继续搜索直到局面恢复“静止”才调用评估函数。
----------------------------------------
题目: 随机博弈 (Stochastic Game) 与马尔可夫决策过程 (MDP) 的主要区别是什么？
答案: MDP 是<b>单智能体</b>、多状态的决策过程；<br>随机博弈是<b>多智能体</b>、多状态的博弈过程。
----------------------------------------
题目: 在多智能体强化学习中，为什么独立使用 Q-learning 会遇到困难？
答案: 因为每个智能体都在更新策略，导致对于单个智能体而言，<b>环境是非固定的</b> (Non-stationary)，这违反了 Q-learning 的基本假设。
----------------------------------------
题目: 纳什 Q-learning (Nash Q-learning) 的基本思想是什么？
答案: 在每个状态下，求解当前阶段的<b>纳什均衡</b>策略，并使用纳什均衡的值来更新 Q 函数。
----------------------------------------
题目: 本章小结：请总结对抗搜索的核心知识体系。
答案: 1. <b>基础</b>：博弈分类、纳什均衡。<br>2. <b>算法</b>：Minimax（完全理性假设）、$\alpha-\beta$ 剪枝（$\alpha \ge \beta$ 剪枝）、截断搜索（评估函数）。<br>3. <b>优化</b>：静止搜索（解决水平线效应）。<br>4. <b>拓展</b>：多智能体博弈（随机博弈、纳什 Q-learning）。
----------------------------------------


==================== 来自文件: data/问答题/13.json ====================

题目: 【大模型定义】<br>LLM (Large Language Model) 的三大“大”特征是指？
答案: 1. <b>训练数据大</b>：以TB为单位，涵盖全网文本。<br>2. <b>参数规模大</b>：数十亿至万亿级（如GPT-4 PPT中提及约1.8万亿参数）。<br>3. <b>耗资巨大</b>：训练成本高昂（如GPT-4训练成本约7800万美元）。
----------------------------------------
题目: 【核心特征】<br>什么是大模型的“涌现能力” (Emergent Ability)？
答案: 指当模型规模（参数、数据、算力）超过某个<b>临界点</b>时，模型突然获得在较小模型上不存在或表现极差的新能力（如思维链 CoT）。<br><i>类比：水在0度结冰的<b>相变</b>。</i>
----------------------------------------
题目: 【核心特征】<br>什么是“上下文学习” (In-Context Learning, ICL)？它会更新模型参数吗？
答案: 定义：模型无需更新内部参数，仅通过在<b>提示词</b>(Prompt)中提供<b>示例</b>，就能即时学会并完成新任务。<br><b>不会更新模型参数</b>。
----------------------------------------
题目: 【核心特征】<br>为什么基座模型需要“对齐” (Alignment)？
答案: 因为预训练后的基座模型是“野生”的，其核心能力是“续写”而非“回答”。<br>对齐是为了让模型符合人类的意图和价值观，遵循 <b>3H原则</b>：<br>1. <b>Helpful</b> (有帮助)<br>2. <b>Honest</b> (诚实)<br>3. <b>Harmless</b> (无害)
----------------------------------------
题目: 【关键技术】<br>RLHF 是什么？它在大模型训练中的作用是什么？
答案: 全称：<b>Reinforcement Learning from Human Feedback</b> (从人类反馈中强化学习)。<br>作用：在SFT（监督微调）之后，进一步通过奖励模型和强化学习，让模型学会判断“哪个回答更好”，从而注入人类的<b>价值观</b>和<b>偏好</b>。
----------------------------------------
题目: 【技术演进】<br>Transformer 架构相比 RNN/LSTM 的核心优势是什么？
答案: 1. <b>并行计算</b>：抛弃了循环结构，可以同时处理整个序列。<br>2. <b>长距离依赖</b>：通过<b>自注意力机制</b> (Self-Attention)，直接捕捉序列中任意两个词之间的关系，无视距离。
----------------------------------------
题目: 【技术演进】<br>BERT 和 GPT 在架构和预训练任务上的主要区别？
答案: <b>BERT</b>：使用 <b>Encoder</b>（编码器），<b>双向</b>上下文，任务是<b>掩码</b>语言模型（完形填空）。<br><b>GPT</b>：使用 <b>Decoder</b>（解码器），<b>单向</b>（自回归），任务是<b>预测下一个词</b>。
----------------------------------------
题目: 【Scaling Law】<br>根据 DeepMind 的 Chinchilla (龙猫) 研究，模型参数量 (N) 和训练数据量 (D) 的最佳比例是多少？
答案: <b>D ≈ 20N</b><br>即训练数据量(tokens)应该是模型参数量的 <b>20倍</b>。<br><i>启示：在同等算力下，应该用更多的数据训练相对较小的模型（相比于GPT-3）。</i>
----------------------------------------
题目: 【分布式训练】<br>什么是“数据并行” (Data Parallelism)？
答案: 核心思想：<b>复制模型，分发数据</b>。<br>每个GPU持有一个完整的模型副本，处理不同的数据微批次(Micro-batch)，最后通过 <b>All-Reduce</b> 同步所有GPU的梯度。
----------------------------------------
题目: 【分布式训练】<br>ZeRO (零冗余优化器) 的三个阶段分别切分了什么？
答案: <b>ZeRO-1</b>：切分<b>优化器状态</b> (Optimizer States)。<br><b>ZeRO-2</b>：切分<b>梯度</b> (Gradients)。<br><b>ZeRO-3</b>：切分<b>模型参数</b> (Parameters)。<br><i>ZeRO-3 显存节省最多，允许在少量GPU上训练极大模型。</i>
----------------------------------------
题目: 【概念辨析】<br>在大模型开发范式中，从 BERT 到 GPT-3 发生了什么转变？
答案: 从 <b>“预训练 + 微调”</b> (Fine-tuning) 范式<br>转变为<br><b>“预训练 + 提示”</b> (Prompting) 范式。<br><i>即不再需要为每个任务单独微调参数，而是通过Prompt激发模型能力。</i>
----------------------------------------
题目: 【分布式训练】<br>什么是“显存墙”？训练一个175B参数的模型(FP32)仅参数本身需要多少显存？
答案: 显存墙指单张GPU显存不足以容纳大模型。<br>1750亿参数 * 4字节 (FP32) ≈ <b>700 GB</b>。<br><i>（这还不包括梯度、优化器状态和激活值）。</i>
----------------------------------------
题目: 【技术演进】<br>DeepSeek (深度求索) 模型的主要优势是什么？
答案: 1. <b>成本低</b>：打破大算力依赖。<br>2. <b>性能强</b>：推理能力出色（深度思考）。<br>3. <b>开源</b>：便于部署和打破垄断。
----------------------------------------


==================== 来自文件: data/问答题/14.json ====================

题目: 【总结】第十五章 大模型推理技术的核心脉络是什么？
答案: 本章主要分为三个部分：<br>1. <b>推理及优化</b>：关注如何解决大模型部署的“显存受限”和“串行延迟”瓶颈。核心技术包括<b>模型压缩</b>（量化、剪枝、蒸馏）和系统级优化（KV Cache、运行时批处理）。<br>2. <b>生成式推理策略</b>：关注解码过程（Decoding）。从确定性策略（贪心、束搜索）演变为随机采样（Top-k, Top-p），以及前沿的<b>推测性解码</b>。<br>3. <b>提示工程</b>：关注如何通过Prompt激活模型潜能。核心技术包括<b>思维链</b>（CoT）及其变体、<b>ReAct</b>（推理+行动）范式。
----------------------------------------
题目: 大模型中 Inference（推理/推断）与 Reasoning（推理/逻辑）的区别是什么？
答案: 1. <b>Inference</b> (推断/应用)：指模型训练完成后，<b>部署</b>并处理新数据以生成预测的过程。关注效率、速度（工程侧）。<br>2. <b>Reasoning</b> (逻辑推理)：指模型内在的<b>思考</b>、分析复杂问题的能力（如CoT）。关注智能表现、中间思维步骤（算法侧）。
----------------------------------------
题目: 大模型推理面临的“三重瓶颈”是什么？
答案: 1. <b>巨大的模型尺寸</b>：海量参数导致显存占用极高（Memory Bound）。<br>2. <b>自回归解码的串行性</b>：逐Token生成，无法并行，延迟随序列长度线性增长。<br>3. <b>自注意力机制的二次复杂度</b>：计算量与序列长度N的<b>平方</b>（$O(N^2)$）成正比。
----------------------------------------
题目: 为什么说大模型推理的深层本质是“内存受限”（Memory Bound）？
答案: 尽管GPU计算能力强大，但在LLM推理中，计算核心大部分时间都在等待数据从<b>高带宽内存 (HBM)</b> 传输。每生成一个Token都需要<b>加载全部模型参数</b>和KV缓存，导致计算单元闲置。
----------------------------------------
题目: 量化（Quantization）的核心原理和优势是什么？
答案: **原理**：降低模型参数和激活值的<b>数值精度</b>（如FP16转INT8/INT4）。<br>**优势**：<br>1. 显著减小模型体积，降低<b>显存</b>需求。<br>2. 在相同内存带宽下传输更多参数，提升<b>推理速度</b>。
----------------------------------------
题目: 结构化剪枝 vs 非结构化剪枝
答案: 1. <b>非结构化剪枝</b>：移除<b>单个参数</b>，造成不规则稀疏。硬件难以利用。<br>2. <b>结构化剪枝</b>：移除整个<b>神经元</b>、注意力头或层。<b>硬件友好</b>，可直接转化为更小的矩阵计算，实现加速。
----------------------------------------
题目: 知识蒸馏（Knowledge Distillation）在LLM中的应用？
答案: 将庞大复杂的“<b>教师模型</b>”的知识迁移到更小、更高效的“<b>学生模型</b>”中。<br>（例如：DeepSeek-R1验证了通过数据蒸馏将大模型能力迁移到小模型）。
----------------------------------------
题目: KV缓存（KV-Cache）的作用是什么？
答案: **作用**：解决自回归解码中的<b>重复计算</b>问题。<br>**原理**：在“解码”阶段，只计算新Token的Q、K、V，并<b>复用</b>缓存中的旧K、V。<br>**代价**：以<b>显存换速度</b>（显存消耗随序列长度增加）。
----------------------------------------
题目: 运行时批处理（In-Flight Batching）解决了什么问题？
答案: 解决了传统批处理需要等待同批次中最长序列完成的问题。它允许服务器在运行时立即<b>移除已完成</b>的序列，并<b>加入新请求</b>，大幅提高GPU利用率和吞吐量。
----------------------------------------
题目: 贪心搜索（Greedy Search）与束搜索（Beam Search）的区别？
答案: 1. <b>贪心搜索</b>：每步只选概率<b>最高</b>的1个Token。易陷入局部最优。<br>2. <b>束搜索</b>：每步维护 <b>K个</b> (Beam Width) 最优候选序列。具有前瞻性，生成质量更高。
----------------------------------------
题目: Top-k 采样 vs Top-p (核) 采样
答案: 1. <b>Top-k</b>：仅从概率最高的 <b>K个</b> Token中随机选择。缺点是K值固定。<br>2. <b>Top-p</b> (Nucleus)：从<b>累积概率</b>达到阈值 P 的动态集合中选择。更灵活，平衡了多样性和准确性。
----------------------------------------
题目: 推测性解码（Speculative Decoding）的工作原理是什么？
答案: 利用“大模型+小模型”协同：<br>1. <b>草稿生成</b>：小模型快速生成多个候选Token。<br>2. <b>并行验证</b>：大模型<b>并行验证</b>这些草稿。<br>优势：利用大模型并行计算能力，显著降低延迟。
----------------------------------------
题目: 为什么中间Token（思维链）对Transformer推理至关重要？
答案: Transformer通过生成中间Token（思维链），实际上增加了逻辑电路的深度（<b>时间换空间</b>）。这使得固定大小的模型能够解决需要更多计算步骤的复杂问题。
----------------------------------------
题目: 什么是思维链（CoT）及其核心作用？
答案: **定义**：引导模型将复杂问题分解为一系列<b>中间推理步骤</b>。<br>**作用**：显著提升模型在多步推理任务上的准确性。CoT是大模型达到一定规模后<b>涌现</b>的能力。
----------------------------------------
题目: Zero-shot CoT 的经典提示词是什么？
答案: <b>Let's think step by step.</b> （让我们逐步思考。）
----------------------------------------
题目: ReAct (Reason+Act) 框架的核心思想是什么？
答案: 结合了<b>推理</b> (Reasoning) 和<b>行动</b> (Acting)。<br>让模型交错生成推理轨迹（思考下一步做什么）和具体动作（调用工具/API），从而解决需要与<b>外部环境交互</b>的复杂任务。
----------------------------------------
题目: 推理性能评估的关键指标有哪些？
答案: 1. <b>延迟</b> (Latency)：包括 <b>TTFT</b> (首字生成时间) 和 <b>ITL</b> (Token间延迟)。<br>2. <b>吞吐量</b> (Throughput)：单位时间处理的Token数。<br>3. <b>成本</b>：每百万Token的费用。
----------------------------------------
题目: 常见的LLM评估基准（Benchmark）有哪些？
答案: 1. <b>MMLU</b>：通用知识和推理。<br>2. <b>HumanEval</b>：<b>代码</b>生成能力。<br>3. <b>TruthfulQA</b>：评估真实性，检测“<b>幻觉</b>”。
----------------------------------------


==================== 来自文件: data/问答题/16.json ====================

题目: 【总结】多模态大模型（MLLM）的经典架构包含哪四个核心模块？
答案: 1. <b>图像预处理</b>（Image Preprocessing）：如Patch Partitioning。<br>2. <b>多模态编码器</b>（Multimodal Encoder）：接收且有效编码，如CLIP。<br>3. <b>投影器</b>（Projector）：多模态数据<b>对齐</b>，映射到文本空间。<br>4. <b>大语言模型</b>（LLM Backbone）：接收对齐信号并执行推理。
----------------------------------------
题目: 多模态大模型发展经历的三个主要阶段是什么？
答案: 1. **第一阶段**：支持<b>低分辨率</b>（224x224），聚焦模态对齐的原型验证（如CLIP, BLIP2, LLaVA）。<br>2. **第二阶段**：增加<b>目标定位</b>能力，服务于Agent和机器人落地（如Qwen-VL）。<br>3. **第三阶段**：支持<b>高分辨率</b>文档图像，缓解语言模型能力下降问题。
----------------------------------------
题目: 什么是 **CLIP** (Contrastive Language-Image Pretraining) 的核心原理？
答案: 通过<b>对比学习</b>（Contrastive Learning）的方法，学习图像与文本的<b>共享嵌入空间</b>。<br>使语义相近的图像和文本在空间中靠近，语义不相关的彼此远离。
----------------------------------------
题目: 在MLLM架构中，**Projector（投影器）** 的作用是什么？列举两种常见类型。
答案: **作用**：将<b>视觉嵌入</b>映射对齐到<b>文本空间</b>，使LLM能理解视觉特征。<br>**常见类型**：<br>1. <b>线性投影</b>/MLP（如LLaVA）：简单高效。<br>2. <b>Q-Former</b>（如BLIP2）：基于注意力机制，用可学习的查询向量提取特征。
----------------------------------------
题目: 多模态模型中，LLM Backbone 融合视觉特征的两种主要架构方法（Method A vs Method B）有什么区别？
答案: 1. **Method A（统一嵌入解码器架构）**：将图像Patch转换为Token，直接与文本Token<b>拼接</b>（Concat），作为LLM的输入（如LLaVA）。<br>2. **Method B（跨模态注意力架构）**：图像特征不直接作为Input Token，而是通过<b>交叉注意力</b>（Cross-Attention）层注入到LLM中（如Flamingo）。
----------------------------------------
题目: 什么是 **Multimodal Chain-of-Thought (CoT)**？与标准推理有何不同？
答案: **定义**：基于多模态证据，在得出结论前先构建<b>中间推理步骤</b>。<br>**标准格式**：<输入 &rarr; 输出><br>**CoT格式**：<输入 &rarr; <b>推理过程</b> &rarr; 输出>
----------------------------------------
题目: 多模态智能体（Multimodal Agent）的定义及其两大分类是什么？
答案: **定义**：能遵循语言指令，在环境中执行操作并调用工具的智能体。<br>**分类**：<br>1. <b>自主智能体</b>（Autonomous）：用于任务自动化，如Auto-UI, WebArena。<br>2. <b>对话智能体</b>（Conversational）：强调个性化与交互，如CAMEL, Generative Agents。
----------------------------------------
题目: 在PPT提到的 **ClevrCount** 实战任务中，使用了什么算法进行训练？奖励函数如何设计？
答案: **算法**：<b>GRPO</b> (Group Relative Policy Optimization)。<br>**奖励函数**：包含两部分：<br>1. <b>格式奖励</b>（Format Reward）：确保输出符合XML标签格式。<br>2. <b>准确性奖励</b>（Accuracy Reward）：比较模型输出数字与Ground Truth是否一致。
----------------------------------------
题目: 什么是图像预处理中的 **Patch Partitioning**？
答案: 将图像分割成固定大小的“<b>补丁</b>”（Patches）并排成<b>序列</b>。目的是解决原始图像直接输入Transformer面临的维度过高问题，随后通常会经过<b>线性投影</b>。
----------------------------------------
题目: 列举几个音频感知（Audio Understanding）的代表性模型。
答案: 1. <b>SALMONN</b>：实现语音、音乐、环境音的统一理解。<br>2. <b>SpeechGPT</b>：专注于人类语音模态（ASR, TTS）。<br>3. <b>AudioGPT</b>：利用LLM作为控制器调用音频专家模型。
----------------------------------------
题目: 视频理解模型（如Video-LLaVA）相比图像模型的核心挑战是什么？
答案: 需要处理<b>动态时空特征</b>（Spatial-Temporal）。不仅要理解每一帧的静态内容，还要将视频的时空特征与文本语义进行高效对齐，以实现对动作、事件和因果关系的推理。
----------------------------------------
题目: 在多模态任务中，“Any-to-Any”指的是什么？
答案: 指大模型能够接收文本、音频、图像、视频中的<b>任意组合</b>作为<b>输入</b>，并自由生成这些模态的<b>任意组合</b>作为<b>输出</b>（如NExT-GPT）。
----------------------------------------
