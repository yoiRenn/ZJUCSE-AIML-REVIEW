# 《人工智能与机器学习》传奇神课复盘

## 第一部分：机器学习 (ML)

我们从概念学习出发，学了 Find-S、候选消除算法，然后发展到线性模型。我记得考试有一道超级论述题，考察了**基函数扩展法**，我基本就是围绕着“升维到高维空间转化为线性问题，用线性模型的方法来解决”的思路完成了整道题，再加上我对傅里叶变换以及一些线性代数的知识完成的。我还额外复习了 LDA 当然也没考。

### 决策树与统计学习
接下来进入了决策树，我们的脚步踏入了统计学习。我们学了 ID3, C4.5, CART 三种算法。这是这次考试的最后一道论述题，他考了我**回归树**的知识。虽然我对这部分其实相当陌生，但我模糊的印象中**叶子节点就是样本的均值**（预测值），然后围绕这一点展开了回答。针对连续值的处理，我的理解还是 C4.5 算法中二分法的思想。总的来说决策树就是用规则集合来表示规律（正如 PPT 中说的“合取的析取式”）。

至于 SVM 和随机森林，受限于课程限制和我的归纳偏置（我觉得这些算法都太老了），没怎么深入了解。

### 神经网络：连接主义的复兴
接下来就是传奇中的传奇，经典中的经典，神经网络。
* **梯度：** 刷新认知的一点——一个标量对矩阵的导数，就是梯度。
* **优化：** 基于优化的基础，梯度下降算法是很好理解的。进一步的 SGD 容易发生 Zigzag 现象，从而得到 Mini-batch SGD，也就是我们代码中经常调的那个 batch 参数。
* **BP 算法：** 如果只按照链式法则去求导，很容易遇到一个矩阵对矩阵求导的问题（得到超级无敌大且稀疏的张量）。BP 算法巧妙地避免了这一点。最后还学了动量法（Momentum）。
* **XOR 问题：** 感知机处理不了非线性边界。除了用 MLP+BP，其实**手动构造非线性特征**（比如 $x_1 \cdot x_2$ 作为第三个维度）也能解决，这样就是立方体的几个顶点，一个平面就可分了。
 * 但是为什么MLP+BP才是划时代的创新而这种手动特征处理不是呢？因为我们希望的是模型能够自己学到这些乱七八糟的特征，而不用人来上手。此外，MLP+BP伟大的是BP，通用近似定理很早就存在了，所以人们都知道MLP可以，但是因为导数会导出来超级大张量导致没办法算梯度，没办法训练。

### 强化学习
从有模型（DP/贝尔曼方程）到无模型（MC/TD）。从 Sarsa 到 Q-Learning，再到引入神经网络的 DQN。虽然 DRL 没考太细，但那个迷宫寻路的逻辑（QLearning 和 Sarsa 怎么走完迷宫）我已经完全跑通了。

### 聚类
K-Means 适合球形数据。考了一个 **GMM (高斯混合模型)**，它用 **EM 算法** 求解。得到的不是非黑即白的分类，而是每个点属于每个簇的**后验概率**（~~我好像考试的时候写了个什么期望最大概率~~）。
### 其他 ML 碎碎念
* **Loss Function：** 回归用 MSE，分类用 CrossEntropy（交叉熵）。

---

## 第二部分：AI 搜索

这部分我们和上学期的优化理论结合了起来。
* **基础搜索：** BFS, DFS, UCS（就是Dijkstra）, IDS, A*。
* **局部搜索：** 爬山法、模拟退火（解决非线性整数规划的神器）、遗传算法。

**真正的神课内容是这些：**
* **实时搜索 (RTA\*, LRTA\*)：** 面临极短时间限制必须给出下一步。RTA* 是一步到位的次优更新，LRTA* 则是通过更新 $h(n)$ 一点点**填平沟壑**（最小值更新），保证不陷死在局部。
* **增量式搜索 (D\* Lite)：** 这个学得最痛苦但也最爽。从终点往起点搜，利用 **$g$ 和 $rhs$ 的双键值排序**。环境变了不需要重跑，只更新受影响的节点（不一致的节点）。这种“一步前瞻”和复用结果的思想，简直是数据结构的巅峰。

当然公式化的对抗搜索也是有的，Minimax 算法、Alpha-Beta 剪枝，以及多智能体的纳什均衡等，了解即可。

---

## 第三部分：LLM —— 收获最大的部分

我们的 PPT 顺序特别乱，我按照我整理完的思路讲一下。

### 1. NLP 的前世
一切的起点是 NLP 问题。
* **Word2Vec：** 解决了 One-hot 稀疏和无语义的问题，把词变成了向量（语义映射）。
* **RNN：** 引入了时间步 $h_t$，处理序列数据。但反向传播时面临**梯度消失**和**梯度爆炸**（连乘效应）。
* **LSTM：** 引入门控机制解决了梯度问题，但依然必须**串行训练**，导致根本无法捕捉超长长期依赖关系。

### 2. Transformer：划破长夜的惊雷
2017 年，Transformer 横空出世，彻底改变了人类对 AI 的认识。
**核心公式：**
$$Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V$$
* **机制：** $Q$ (Query) 查字典，$K$ (Key) 被查，$V$ (Value) 提取内容。矩阵乘法让它可以**并行计算**，且无论距离多远，相关性一步算出。
* **位置编码：** 因为 Self-Attention 是置换不变的，必须手动告诉模型谁在前谁在后。

**架构细节：**
* **Encoder：** 输入 -> **LN (Layer Normalization)** -> Self-Attention -> Residual -> LN -> FFN。把词向量投影到高维空间拆解含义。
* **Decoder：** **Masked Self-Attention**（强制不能看下文）-> **Cross Attention**（看 Encoder 也就是老师给的资料）-> 输出。
* **LLM 本体：** 像 GPT-3（96层），本质上就是 Decoder-only 模块的无限堆叠。

### 3. 注入灵魂：从基座到助手
光有基座模型（Base Model）只会瞎续写，我们需要它听话、懂专业。
* **RLHF (Reinforcement Learning from Human Feedback)：**
    1.  **SFT：** 喂高质量问答对，教它“讲人话”。
    2.  **RM (Reward Model)：** 训练一个打分模型，模仿人类价值观。
    3.  **PPO：** 让模型根据 RM 的分数调整策略。*（注：这里加入了 **KL 散度惩罚**，防止模型为了拿高分而“作弊”或偏离 SFT 模型太远）。*
* **LoRA：** 微调时不改动大参数 $W$，而是训练旁路 $A \times B$。参数量 $2nr \ll n^2$，四两拨千斤，让模型快速掌握专业知识。
* **RAG：** 给模型外挂数据库。不是直接 Attention 数据库，而是先**检索**相关片段，拼接到 Prompt 里，让模型基于这些资料回答。

---

## 第四部分：推理 (Inference) 与 逻辑 (Reasoning)

模型练好了，怎么用好又是另一门学问。

### 1. Inference：让它跑得快
这部分侧重模型部署以后推理的速度和性能。
* **采样策略：**
    * **温度 (Temperature)：** 调整 Softmax 的平滑度。$T$ 越大，概率分布越平，回答越有创造力。
    * **Top-p (Nucleus)：** 截断尾部低概率词，只在累积概率 $p$ 的头部词里抽，保留优质长尾词。
* **三大瓶颈与解法：**
    1.  **$O(N^2)$ 复杂度 & 显存墙** -> **KV Cache**：缓存 $K$ 和 $V$ 矩阵，虽然变成了线性增长，但对显存带来了极高的需求（Memory Bound）。
    2.  **模型太大** -> **量化 (Quantization)**：FP16 转 INT8/INT4，精度换空间。
    3.  **串行生成慢** -> **推测性解码 (Speculative Decoding)**：小模型猜，大模型批改。并行检查，速度大大提升。

### 2. Reasoning：让它变得聪明
* **CoT (Chain of Thought)：**
    引导模型拆解复杂问题，展示中间思考过程。**本质是用时间换空间**，把一个固定深度的模型，通过多轮输出串联成一个超级深的模型，从而处理复杂逻辑。
* **进阶架构：**
    * **ReAct：** 推理 (Reason) + 行动 (Act)。推理指导行动，行动辅助推理（比如调用搜索工具）。
    * **ToT (Tree of Thoughts)：** 树状思维，不一条路走到黑，而是像下棋一样推演多种可能性。

---

## 第五部分：多模态 (MLLM) —— 通向未来

这部分考前比较轻视，现在补全一下逻辑。核心就是：**给 LLM 装上眼睛**。

**公式：MLLM = 视觉编码器 + 连接器 + LLM基座**

1.  **视觉编码器 (Vision Encoder)：** 比如 ViT。把图片切块，变成一堆向量。
2.  **连接器 (Projector) —— 关键点！**
    * **Method A (如 LLaVA)：线性投影**。用一个简单的矩阵把图像向量“翻译”成文本向量的维度，直接拼在 Prompt 前面。
    * **Method B (如 Q-Former)：交叉注意力**。用专门的 Query 向量去图像里“抓”特征，再喂给 LLM。
3.  **LLM 基座：** 大脑不变，通过连接器传来的信号理解世界。

---
## 第六部分：课程之外 —— 现在的LLM走到哪一步了？
--- 

**总结：**
就这样一步步深入，把我对这门课的最后印象抽丝剥茧完全的过一遍。因为我说白了要不是这门课 90% 的知识我接下来很长一段时间都是糊成一团的。

尤其是 LLM 部分，明明是这么伟大这么划时代的革命性创新，不这样细细的扣下来太可惜了。总的来说我还是十分感谢这门课的，尽管很史，但是我踏踏实实学到东西了。