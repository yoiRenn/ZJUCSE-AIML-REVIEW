[
    {
        "q": "第一章中列举了哪些机器学习的主要研究领域？（请至少列举3个，除深度学习/强化学习外）",
        "a": "1. 符号机器学习（如决策树）；\n2. 计算学习理论（如PAC、SVM）；\n3. 集群机器学习（如Ensemble Learning、Boosting）；\n4. 流形（Manifold）学习；\n5. Ranking学习。"
    },
    {
        "q": "多元线性回归在满秩情况下的闭式解（Closed-form solution）公式是什么？",
        "a": "$$\\hat{w}^* = (X^T X)^{-1} X^T y$$"
    },
    {
        "q": "感知机（Perceptron）可以通过不同的权重设置实现哪些基本的逻辑门电路？",
        "a": "与门（AND）、或门（OR）、与非门（NAND）。"
    },
    {
        "q": "聚类性能度量中，外部指标（External Index）和内部指标（Internal Index）的核心区别是什么？",
        "a": "外部指标是将聚类结果与某个“参考模型”（即真实类别/Ground Truth）进行比较；而内部指标是不利用外部参考，直接考察聚类结果本身的紧密性（intra-cluster）和分离度（inter-cluster）。"
    },
    {
        "q": "深度强化学习（DQN）在训练时面临哪两大核心挑战，导致了训练的不稳定性？",
        "a": "1. **样本相关性（Sample Correlation）**：序列决策获取的样本存在时域关联，违反了独立同分布假设；\n2. **非平稳目标（Non-stationary Targets）**：使用TD target作为标签，而标签本身随着网络参数更新而变化。"
    },
    {
        "q": "知识图谱（Knowledge Graph）构建的核心技术环节包含哪三个步骤？",
        "a": "1. **实体抽取**（Entity Extraction）；\n2. **关系抽取**（Relation Extraction）；\n3. **知识融合**（Knowledge Fusion）。"
    },
    {
        "q": "纳什 Q-learning 算法主要存在哪两个问题？",
        "a": "1. 计算复杂度非常高；\n2. 当其他智能体的策略不可用时可能无法工作（需要对手建模）。"
    },
    {
        "q": "BERT 模型采用哪两个预训练任务来学习双向上下文表示？",
        "a": "1. **掩码语言模型**（Masked Language Model, MLM）：随机遮盖输入中15%的token并预测；\n2. **下一句预测**（Next Sentence Prediction, NSP）：判断两个句子是否为连续的上下句。"
    },
    {
        "q": "Transformer 中自注意力机制（Self-Attention）的数学计算公式是什么？",
        "a": "$$Attention(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$$"
    },
    {
        "q": "LoRA (Low-Rank Adaptation) 的核心数学形式是如何表示参数更新的？",
        "a": "$$W_0 + \\Delta W = W_0 + BA$$ \n其中 $W_0$ 是冻结的预训练权重，$B$ 和 $A$ 是低秩矩阵（$B \\in \\mathbb{R}^{d \\times r}, A \\in \\mathbb{R}^{r \\times k}$，且 $r \\ll d$）。"
    },
    {
        "q": "在模型剪枝技术中，什么是动态剪枝（如 IFPruning）？",
        "a": "将提示工程与模型架构融合，允许模型根据用户的具体指令，动态地决定激活模型中的哪些部分（如只激活处理代码生成的神经元），以提高推理效率。"
    },
    {
        "q": "什么是 Any-to-Any 多模态大模型？并举一个代表性模型。",
        "a": "指能够接收文本、音频、图像、视频中任意组合作为输入，并自由生成这些模态任意组合作为输出的模型。\n代表模型：**NExT-GPT**。"
    },
    {
        "q": "在 D* Lite 路径规划算法中，如何根据 g 值和 rhs 值的关系来定义“过一致”（Overconsistent）和“欠一致”（Underconsistent）状态？",
        "a": "1. **过一致**：当 $g(s) > rhs(s)$ 时，表示当前节点到目标的已知路径成本高于理论最小值（通常发生在障碍物移除时）；\n2. **欠一致**：当 $g(s) < rhs(s)$ 时，表示当前节点到目标的已知路径成本低于理论最小值（通常发生在新增障碍物导致路径失效时）。[1]"
    },
    {
        "q": "在智能体（Agent）的状态表示中，沿着复杂度和表达能力增长的轴线，状态可以分为哪三种表示形式？",
        "a": "1. **原子表示**（Atomic）：状态被视为黑盒，没有任何内部结构；\n2. **要素化表示**（Factored）：状态由固定的变量或属性集合描述；\n3. **结构化表示**（Structured）：状态描述对象之间的关系（如逻辑、知识图谱）。[2]"
    },
    {
        "q": "推测性解码（Speculative Decoding）为了加速大模型推理，具体包含哪三个核心步骤？",
        "a": "1. **草稿生成**：使用小模型（Draft Model）快速生成一个包含多个候选 token 的草稿序列；\n2. **并行验证**：使用大模型（Target Model）并行地验证这些草稿 token 的概率分布；\n3. **最终输出**：接受匹配的 token，若发现不匹配则立即修正，并用大模型的预测取代后续草稿。[3]"
    },
    {
        "q": "在比较两个学习算法的性能时，为什么“配对 t 测试”（Paired t-test）通常比在独立样本上测试能产生更紧密的置信区间？",
        "a": "因为配对测试是在**同一个**测试集上评估两个算法，消除了由两个不同测试样本集的组成差异（Sample Variance）所带来的随机方差，使得观察到的差异主要来源于算法本身的差异。[4]"
    },
    {
        "q": "在多模态大模型中，GILL 模型和 EMU 模型在核心任务定位上有什么主要区别？",
        "a": "1. **GILL**：侧重于**感知与理解**，通过图像-语言学习框架实现对视觉输入的理解和推理；\n2. **EMU**：侧重于**内容生成**，接收文本提示并通过高效的生成架构同步创造高保真的图像内容。[5]"
    },
    {
        "q": "弹性网络（Elastic Net）的损失函数是如何结合 Ridge 和 Lasso 的正则化项的？（请描述其数学构成）",
        "a": "它在平方误差项的基础上，增加了 L1 范数和 L2 范数的**加权和**。公式中包含一个混合比例参数 $\\rho$，形式为 $\\lambda [\\rho \\sum |\\theta|_1 + (1-\\rho) \\sum \\theta^2]$，从而兼具稀疏性（特征选择）和稳定性。[6]"
    },
    {
        "q": "DeepMind 的 Chinchilla 研究得出的“Scaling Law”与 OpenAI 最初的结论有何不同？这对数据工程有何启示？",
        "a": "不同点：Chinchilla 发现模型参数量 ($N$) 和训练数据量 ($D$) 应该近似**等比例（线性）增长** ($D \\approx 20N$)，而不是优先放大模型参数。\n启示：这意味着高质量文本数据成为新瓶颈，且催生了使用模型生成**合成数据**（Synthetic Data）进行训练的需求。[7]"
    },
    {
        "q": "在 ClevrCount 的多模态训练实战中，自定义的“准确性奖励函数”（Accuracy Reward）采用了哪两种验证方式来判定模型输出是否正确？",
        "a": "1. **符号验证**（Symbolic verification）：尝试解析输出中的数字内容并进行数值比较；\n2. **字符串匹配**（String matching）：如果符号验证失败，则提取 `<answer>` 标签中的内容与真值（Ground Truth）进行文本比对。[8]"
    },
    {
        "q": "在 Find-S 算法中，为什么说它输出的是“极大特殊”（Maximally Specific）假设？",
        "a": "因为它将假设 $h$ 初始化为最特殊的假设（全为 $\\emptyset$），然后在处理正例时，只进行能够覆盖该正例的**极小一般化**。这意味着它生成的假设在满足所有正例的前提下，尽可能地保持特殊（覆盖实例最少）。[9, 10]"
    },
    {
        "q": "对于纳什 Q-learning (Nash Q-learning)，其核心迭代过程是如何利用纳什均衡值的？",
        "a": "它在每个状态下求解当前阶段的博弈矩阵的**纳什均衡策略** $\\pi^*$，然后使用该均衡策略对应的纳什值 $v_{Nash}$ 来更新 Q 函数，而不是像普通 Q-learning 那样直接取 max。[11]"
    }
]