[
    {
        "q": "聚类的基本目标是什么？",
        "a": "将数据集中的样本划分为若干个通常不相交的子集（“簇”，cluster），使得<b>簇内相似度</b>高，且<b>簇间相似度</b>低。"
    },
    {
        "q": "聚类性能度量中的“外部指标”和“内部指标”有何区别？",
        "a": "<b>外部指标</b> (External Index)：将聚类结果与某个<b>参考模型</b>（如已知的类标）进行比较。<br><b>内部指标</b> (Internal Index)：<b>直接考察</b>聚类结果而不用任何参考模型。"
    },
    {
        "q": "列举三个常见的聚类外部指标（External Indices）。",
        "a": "1. <b>Jaccard系数</b> (JC)<br>2. <b>FM指数</b> (FMI)<br>3. <b>Rand指数</b> (RI)<br>（注：这些指标在[0,1]区间内，值越大越好）"
    },
    {
        "q": "DB指数 (DBI) 和 Dunn指数 (DI) 的评价标准是什么？",
        "a": "<b>DBI</b>：<b>越小越好</b>（表示簇内距离小，簇间距离大）。<br><b>Dunn指数</b>：<b>越大越好</b>（表示簇间最小距离与簇内最大直径之比大）。"
    },
    {
        "q": "闵可夫斯基距离 (Minkowski distance) 中 p=1 和 p=2 分别对应什么距离？",
        "a": "p=1：<b>曼哈顿距离</b> (Manhattan distance)<br>p=2：<b>欧氏距离</b> (Euclidean distance)"
    },
    {
        "q": "在距离计算中，如何处理“无序属性” (Non-ordinal attribute)？",
        "a": "可以使用 <b>VDM</b> (Value Difference Metric)。它基于属性值在各簇中出现的频率分布来计算两个离散值之间的距离。"
    },
    {
        "q": "原型聚类 (Prototype-based clustering) 的核心假设是什么？",
        "a": "假设聚类结构能通过<b>一组原型</b>刻画。通常先对原型初始化，再进行迭代更新求解。"
    },
    {
        "q": "k均值 (k-Means) 算法的优化目标是什么？",
        "a": "<b>最小化平方误差</b> E，即簇内样本围绕簇均值向量的紧密程度。E值越小，簇内样本相似度越高。"
    },
    {
        "q": "LVQ (学习向量量化) 算法与一般聚类算法最大的不同是什么？",
        "a": "LVQ 假设数据样本带有<b>类别标记</b>（监督信息），利用这些监督信息来辅助学习一组原型向量。"
    },
    {
        "q": "EM 算法 (Expectation-Maximization) 的两个主要步骤是什么？",
        "a": "<b>E步</b> (Expectation)：以当前参数推断隐变量的分布（计算<b>期望</b>）。<br><b>M步</b> (Maximization)：寻找能<b>最大化</b>期望似然的参数。"
    },
    {
        "q": "高斯混合聚类 (GMM) 采用什么模型来表达聚类原型？",
        "a": "采用<b>概率模型</b>（多元高斯分布）。它假设样本由 k 个混合的<b>高斯分布</b>生成，每个成分对应一个簇。"
    },
    {
        "q": "DBSCAN 算法基于哪两个参数来刻画样本分布的紧密程度？",
        "a": "1. <b>ϵ</b> (epsilon)：邻域半径<br>2. <b>MinPts</b>：邻域内包含的最小样本数"
    },
    {
        "q": "在 DBSCAN 中，什么是“核心对象”？",
        "a": "若某个样本的 ϵ-邻域内<b>至少包含 MinPts 个样本</b>，则该样本点为一个核心对象。"
    },
    {
        "q": "相比于 k-Means，DBSCAN 算法的主要优势是什么？",
        "a": "1. 可以发现<b>任意形状</b>的簇（不仅仅是球形）。<br>2. 对<b>噪声</b>（异常点）不敏感。<br>3. 不需要预先指定簇的个数 k。"
    },
    {
        "q": "AGNES 算法采用的是什么样的层次聚类策略？",
        "a": "<b>自底向上</b> (Bottom-up) 的聚合策略。起初将每个样本看作一个簇，然后不断合并距离最近的两个簇。"
    },
    {
        "q": "AGNES 算法中，计算两个簇之间距离的常用方法有哪些？",
        "a": "1. <b>最小距离</b> (Single Linkage)<br>2. <b>最大距离</b> (Complete Linkage)<br>3. <b>平均距离</b> (Average Linkage)"
    },
    {
        "q": "为什么数据预处理中的“归一化” (Normalization) 对聚类很重要？",
        "a": "因为聚类通常依赖<b>距离计算</b>。如果特征的<b>尺度</b>（Scale）差异很大，数值范围大的特征会主导距离计算，导致聚类结果偏差。"
    },
    {
        "q": "本章小结：请总结 k-Means、DBSCAN 和 AGNES 的分类体系。",
        "a": "1. <b>k-Means</b>：<b>原型聚类</b>（基于均值向量，需预设k，适合球状簇）。<br>2. <b>DBSCAN</b>：<b>密度聚类</b>（基于样本密度连接性，抗噪，适合任意形状）。<br>3. <b>AGNES</b>：<b>层次聚类</b>（自底向上构建树状结构）。"
    }
]