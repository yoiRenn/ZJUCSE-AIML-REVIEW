id,type,gender,word,cn,forms,example,source
101,填空,,经验积累,汤姆·米切尔（Tom Mitchell）对机器学习：计算机程序如何随着____自动提高性能，系统自我改进的过程。,完整：随着经验积累自动提高性能,Chapter1,Anki
102,填空,,模式; 预测或决策,机器学习的核心思想：从数据中发现____ -> 做出____。,完整：从数据中发现模式 -> 做出预测或决策,Chapter1,Anki
103,填空,,显式编程; 自动学习; 数据驱动,机器学习与传统编程的区别：传统编程是____；机器学习是从数据中____和改进（____决策）。,完整：传统编程是显式编程；机器学习是从数据中自动学习和改进（数据驱动）,Chapter1,Anki
104,填空,,容错性; 推广能力,自然智慧的两个重要特点：1. ____; 2. ____（举一反三/泛化能力）。,完整：1. 容错性 2. 推广能力,Chapter1,Anki
105,填空,,样本标签已知; 已经标注,有监督学习（Supervised Learning）：在____的情况下，利用这些参数进行分类器设计。训练样本____（Labeled）。,完整：样本标签已知；训练样本已经标注,Chapter1,Anki
106,填空,,无法预先知道样本标签; 无训练样本,无监督学习（Unsupervised Learning）：在____（____）的情况下进行分类器设计。,完整：无法预先知道样本标签（无训练样本）,Chapter1,Anki
107,填空,,已知; 学习出来,分类与聚类的区别：分类的类别是____的；聚类的类别是____的（未知的）。,完整：分类类别已知；聚类类别是学习出来的,Chapter1,Anki
108,填空,,不主动建模; 预测,懒惰学习（Lazy Learning）：平时仅保存数据，____，直到____时才处理数据。,完整：不主动建模；直到预测时才处理,Chapter1,Anki
109,填空,,延迟学习; 局部估计; 即时计算,懒惰学习的三个显著特征：1. ____; 2. ____; 3. ____。,完整：1. 延迟学习 2. 局部估计 3. 即时计算,Chapter1,Anki
110,填空,,Rosenblatt,1957年谁首次提出了感知器（Perceptron）：____。,完整：Rosenblatt,Chapter1,Anki
111,填空,,XOR 问题,1969年《Perceptron》一书指出感知器无法解决____（异或问题）。,完整：XOR 问题,Chapter1,Anki
112,填空,,MLP + BP算法,1980年代标志着连接主义（神经网络）复兴的算法：____（多层感知机 + 反向传播算法）。,完整：MLP + BP算法,Chapter1,Anki
113,填空,,SVM,1990年代统计学习理论走向成熟的典型代表算法：____（支持向量机）。,完整：SVM,Chapter1,Anki
114,填空,,结构风险最小化,SVM（支持向量机）基于____原则。,完整：结构风险最小化,Chapter1,Anki
115,填空,,深度学习; ImageNet,2012年标志性事件：____兴起；在 ____ 竞赛中取得了最佳效果。,完整：深度学习；ImageNet,Chapter1,Anki
116,填空,,AlphaGo,2016年Google战胜李世石的系统：____。,完整：AlphaGo,Chapter1,Anki
117,填空,,人工智能; 统计学; 信息论; 哲学; 神经生物学,机器学习受到的相关学科影响：____、____、____、____、____。,完整：人工智能、统计学、信息论、哲学、神经生物学,Chapter1,Anki
118,填空,,预测型,网络安全领域的入侵检测通常被看作：典型的____机器学习问题。,完整：预测型,Chapter1,Anki
119,填空,,PageRank,Google搜索引擎的第一桶金算法：____算法。,完整：PageRank,Chapter1,Anki
120,填空,,更简单,奥卡姆剃刀（Occam's Razor）原则：在性能相近的模型中，通常选择____的模型。,完整：更简单的模型,Chapter1,Anki
121,填空,,布尔函数,概念学习（Concept Learning）：从有关某个____的输入输出训练样例中，推断出该函数。,完整：布尔函数,Chapter1,Anki
122,填空,,假设空间,概念学习的搜索过程：在预定义的____中进行搜索，寻找能够最好地拟合训练样例的假设。,完整：假设空间,Chapter1,Anki
123,填空,,未见实例,归纳学习假设：任一假设如果在足够大的训练样例集中很好地逼近目标函数，它也能在____中很好地逼近目标函数。,完整：未见实例,Chapter1,Anki
124,填空,,更一般,假设空间中“一般到特殊”的序关系：当且仅当对于任意实例 x，只要 h_k(x)=1 就能推出 h_j(x)=1 时，称 h_j 比 h_k ____。,完整：更一般,Chapter1,Anki
125,填空,,偏序关系,假设空间上的“一般到特殊”序关系属于：____（Partial Order）。,完整：偏序关系,Chapter1,Anki
126,填空,,极大特殊,Find-S 算法的基本策略：寻找____假设。,完整：极大特殊,Chapter1,Anki
127,填空,,容错性差,Find-S 算法的主要缺点：1. 无法判断唯一性; 2. ____（对噪声敏感）; 3. 无法利用反例。,完整：容错性差,Chapter1,Anki
128,填空,,一致,变型空间（Version Space）：假设空间 H 中与训练样例集 D ____的所有假设组成的子集。,完整：一致,Chapter1,Anki
129,填空,,h(x) = c(x),变型空间中“一致”的定义：假设 h 与训练样例集合 D 一致，当且仅当对 D 中每一个样例，都有____。,完整：h(x) = c(x),Chapter1,Anki
130,填空,,S边界; G边界,候选消除算法表示变型空间通过：1. ____（极大特殊边界）; 2. ____（极大一般边界）。,完整：1. S边界 2. G边界,Chapter1,Anki
131,填空,,极小一般化,候选消除算法中，遇到“正例”时S边界：进行____（变得更一般以包含新正例）。,完整：极小一般化,Chapter1,Anki
132,填空,,极小特殊化,候选消除算法中，遇到“反例”时G边界：进行____（变得更特殊以排除新反例）。,完整：极小特殊化,Chapter1,Anki
133,填空,,大约半数,概念学习中最优的查询策略：产生一个实例，使其满足当前变型空间中____的假设。,完整：大约半数,Chapter1,Anki
134,填空,,存在错误; 目标概念无法被假设空间表示,候选消除算法收敛到一个空的变型空间意味着：训练样例中____，或者____。,完整：存在错误；目标概念无法被假设空间表示,Chapter1,Anki
135,填空,,前提假设,归纳偏置（Inductive Bias）：学习器为了从训练数据中归纳出未见实例的分类，所必须做出的____。,完整：前提假设,Chapter1,Anki
136,填空,,包含在假设空间 H 中,候选消除算法的归纳偏置：目标概念 c ____。,完整：包含在假设空间 H 中,Chapter1,Anki
137,填空,,无偏学习是无用的,无偏的学习器（Unbiased Learner）的问题：____。,完整：无偏学习是无用的,Chapter1,Anki
138,填空,,Find-S; 候选消除算法; 机械式学习,归纳偏置的强弱排列：____ > ____ > ____。,完整：Find-S > 候选消除算法 > 机械式学习,Chapter1,Anki