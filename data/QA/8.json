[
    {
        "q": "评估学习算法精度时，面临的两个关键困难是什么？",
        "a": "1. <b>估计的困难（偏差）</b>：如何使用有限的数据得出对未来数据的准确估计。<br>2. <b>估计的方差</b>：即使是无偏估计，不同的测试集也可能导致不同的结果（数据越少，方差越大）。"
    },
    {
        "q": "样本错误率 (Sample Error, $error_S(h)$) 的定义是什么？",
        "a": "假设 $h$ 在样本集合 $S$ 上错误分类的样本比例。<br>公式：$error_S(h) = \\frac{1}{n} \\sum_{x \\in S} <b>\\delta(f(x), h(x))</b>$<br>其中 $\\delta$ 当预测错误时为1，否则为0。"
    },
    {
        "q": "真实错误率 (True Error, $error_D(h)$) 的定义是什么？",
        "a": "假设 $h$ 在<b>整个概率分布</b> $D$ 上错误分类实例的<b>概率</b>。<br>公式：$error_D(h) = Pr_{x \\in D}[f(x) \\neq h(x)]$。"
    },
    {
        "q": "对于离散值假设，真实错误率 $error_D(h)$ 的 N% 置信区间近似公式是什么？",
        "a": "$$error_S(h) \\pm <b>z_N</b> \\sqrt{\\frac{error_S(h)(1-error_S(h))}{n}}$$ <br> 其中 $n$ 是样本大小，$z_N$ 是<b>置信度常数</b>（如95%对应1.96）。"
    },
    {
        "q": "使用正态分布近似计算二项分布的置信区间时，需要满足什么条件？",
        "a": "1. 样本量 $n \\ge <b>30</b>$。<br>2. $n \\cdot error_S(h) \\cdot (1 - error_S(h)) \\ge <b>5</b>$ (即错误率不太靠近0或1)。"
    },
    {
        "q": "什么是估计量的“偏差” (Bias)？",
        "a": "估计量的<b>期望值</b>与<b>真实参数值</b>之间的差：$Bias = E[Y] - p$。<br>如果偏差为0，则称 $Y$ 为 $p$ 的<b>无偏估计量</b>。"
    },
    {
        "q": "为什么说样本错误率 $error_S(h)$ 是真实错误率 $error_D(h)$ 的无偏估计量？",
        "a": "因为 $error_S(h)$ 服从<b>二项分布</b>，其<b>期望值</b> $E[error_S(h)] = p = error_D(h)$。<br>前提是数据是<b>独立同分布</b>抽取的。"
    },
    {
        "q": "中心极限定理 (Central Limit Theorem) 的核心含义是什么？",
        "a": "当样本量 $n \\to \\infty$ 时，独立同分布随机变量的<b>样本均值</b>所服从的分布趋近于<b>正态分布</b>，无论原始变量服从什么分布。"
    },
    {
        "q": "比较两个假设 $h_1$ 和 $h_2$ 的错误率差异 $d$ 时，差异的方差 $\\sigma_d^2$ 如何计算（假设使用独立样本）？",
        "a": "是两个独立正态分布的<b>方差之和</b>：<br>$$\\sigma_d^2 \\approx \\frac{error_{S_1}(h_1)(1-error_{S_1}(h_1))}{n_1} + \\frac{error_{S_2}(h_2)(1-error_{S_2}(h_2))}{n_2}$$"
    },
    {
        "q": "双侧置信区间与单侧置信区间的置信度有何关系？",
        "a": "正态分布是<b>对称</b>的。一个 $100(1-\\alpha)\\%$ 的双侧置信区间的上界（或下界），对应于一个 <b>100(1-\\alpha/2)%</b> 的单侧置信区间。<br>例如：90%的双侧区间对应95%的单侧区间。"
    },
    {
        "q": "比较两个学习算法（而非特定假设）时，通常采用什么方法？",
        "a": "<b>k-Fold 交叉验证</b> (Cross Validation)。<br>将数据分为 $k$ 份，进行 $k$ 次训练和测试，计算错误率差值的<b>平均值</b> $\\bar{\\delta}$。"
    },
    {
        "q": "在 k-Fold 交叉验证中，计算置信区间为何使用 t分布 而不是 正态分布？",
        "a": "因为我们通常不知道真实的样本标准差，只能用<b>样本标准差</b> $s_{\\delta}$ 进行估计。当样本量较小时，<b>t分布</b>（更宽更矮）能更好地反映这种不确定性。"
    },
    {
        "q": "配对 t-测试 (Paired t-test) 的自由度是多少？",
        "a": "自由度 $v = <b>k - 1</b>$，其中 $k$ 是测试的次数（例如 k-fold 中的 k）。"
    },
    {
        "q": "在实际应用中，k-Fold 交叉验证是否完全满足统计学独立性假设？为什么？",
        "a": "<b>不完全满足</b>。<br>因为不同的训练集之间存在<b>重叠</b>（共享了部分数据），导致生成的假设不完全独立。但它仍提供了良好的近似。"
    },
    {
        "q": "本章小结：算法评估的核心逻辑是什么？",
        "a": "1. 利用<b>统计学</b>方法，用有限样本上的观察精度逼近真实精度。<br>2. 识别<b>估计偏差</b>（期望与真值的差）和<b>估计方差</b>（估计值的波动）。<br>3. 使用<b>置信区间</b>来量化不确定性。<br>4. 使用<b>t-测试</b>等假设检验方法来比较不同算法的性能差异。"
    }
]