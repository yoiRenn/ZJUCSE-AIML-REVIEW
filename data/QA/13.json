[
    {
        "q": "【大模型定义】<br>LLM (Large Language Model) 的三大“大”特征是指？",
        "a": "1. <b>训练数据大</b>：以TB为单位，涵盖全网文本。<br>2. <b>参数规模大</b>：数十亿至万亿级（如GPT-4 PPT中提及约1.8万亿参数）。<br>3. <b>耗资巨大</b>：训练成本高昂（如GPT-4训练成本约7800万美元）。"
    },
    {
        "q": "【核心特征】<br>什么是大模型的“涌现能力” (Emergent Ability)？",
        "a": "指当模型规模（参数、数据、算力）超过某个<b>临界点</b>时，模型突然获得在较小模型上不存在或表现极差的新能力（如思维链 CoT）。<br><i>类比：水在0度结冰的<b>相变</b>。</i>"
    },
    {
        "q": "【核心特征】<br>什么是“上下文学习” (In-Context Learning, ICL)？它会更新模型参数吗？",
        "a": "定义：模型无需更新内部参数，仅通过在<b>提示词</b>(Prompt)中提供<b>示例</b>，就能即时学会并完成新任务。<br><b>不会更新模型参数</b>。"
    },
    {
        "q": "【核心特征】<br>为什么基座模型需要“对齐” (Alignment)？",
        "a": "因为预训练后的基座模型是“野生”的，其核心能力是“续写”而非“回答”。<br>对齐是为了让模型符合人类的意图和价值观，遵循 <b>3H原则</b>：<br>1. <b>Helpful</b> (有帮助)<br>2. <b>Honest</b> (诚实)<br>3. <b>Harmless</b> (无害)"
    },
    {
        "q": "【关键技术】<br>RLHF 是什么？它在大模型训练中的作用是什么？",
        "a": "全称：<b>Reinforcement Learning from Human Feedback</b> (从人类反馈中强化学习)。<br>作用：在SFT（监督微调）之后，进一步通过奖励模型和强化学习，让模型学会判断“哪个回答更好”，从而注入人类的<b>价值观</b>和<b>偏好</b>。"
    },
    {
        "q": "【技术演进】<br>Transformer 架构相比 RNN/LSTM 的核心优势是什么？",
        "a": "1. <b>并行计算</b>：抛弃了循环结构，可以同时处理整个序列。<br>2. <b>长距离依赖</b>：通过<b>自注意力机制</b> (Self-Attention)，直接捕捉序列中任意两个词之间的关系，无视距离。"
    },
    {
        "q": "【技术演进】<br>BERT 和 GPT 在架构和预训练任务上的主要区别？",
        "a": "<b>BERT</b>：使用 <b>Encoder</b>（编码器），<b>双向</b>上下文，任务是<b>掩码</b>语言模型（完形填空）。<br><b>GPT</b>：使用 <b>Decoder</b>（解码器），<b>单向</b>（自回归），任务是<b>预测下一个词</b>。"
    },
    {
        "q": "【Scaling Law】<br>根据 DeepMind 的 Chinchilla (龙猫) 研究，模型参数量 (N) 和训练数据量 (D) 的最佳比例是多少？",
        "a": "<b>D ≈ 20N</b><br>即训练数据量(tokens)应该是模型参数量的 <b>20倍</b>。<br><i>启示：在同等算力下，应该用更多的数据训练相对较小的模型（相比于GPT-3）。</i>"
    },
    {
        "q": "【分布式训练】<br>什么是“数据并行” (Data Parallelism)？",
        "a": "核心思想：<b>复制模型，分发数据</b>。<br>每个GPU持有一个完整的模型副本，处理不同的数据微批次(Micro-batch)，最后通过 <b>All-Reduce</b> 同步所有GPU的梯度。"
    },
    {
        "q": "【分布式训练】<br>ZeRO (零冗余优化器) 的三个阶段分别切分了什么？",
        "a": "<b>ZeRO-1</b>：切分<b>优化器状态</b> (Optimizer States)。<br><b>ZeRO-2</b>：切分<b>梯度</b> (Gradients)。<br><b>ZeRO-3</b>：切分<b>模型参数</b> (Parameters)。<br><i>ZeRO-3 显存节省最多，允许在少量GPU上训练极大模型。</i>"
    },
    {
        "q": "【概念辨析】<br>在大模型开发范式中，从 BERT 到 GPT-3 发生了什么转变？",
        "a": "从 <b>“预训练 + 微调”</b> (Fine-tuning) 范式<br>转变为<br><b>“预训练 + 提示”</b> (Prompting) 范式。<br><i>即不再需要为每个任务单独微调参数，而是通过Prompt激发模型能力。</i>"
    },
    {
        "q": "【分布式训练】<br>什么是“显存墙”？训练一个175B参数的模型(FP32)仅参数本身需要多少显存？",
        "a": "显存墙指单张GPU显存不足以容纳大模型。<br>1750亿参数 * 4字节 (FP32) ≈ <b>700 GB</b>。<br><i>（这还不包括梯度、优化器状态和激活值）。</i>"
    },
    {
        "q": "【技术演进】<br>DeepSeek (深度求索) 模型的主要优势是什么？",
        "a": "1. <b>成本低</b>：打破大算力依赖。<br>2. <b>性能强</b>：推理能力出色（深度思考）。<br>3. <b>开源</b>：便于部署和打破垄断。"
    }
]